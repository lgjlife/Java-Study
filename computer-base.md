
<span id="menu" >

<!-- TOC -->

- [1. 计算机&网络&操作系统](#1-计算机网络操作系统)
  - [1.1. 计算机基础](#11-计算机基础)
    - [1.1.1. 数字系统](#111-数字系统)
      - [1.1.1.1. ASCII](#1111-ascii)
    - [1.1.2. 数据存储](#112-数据存储)
    - [1.1.3. 数据运算](#113-数据运算)
    - [1.1.4. 计算机组成](#114-计算机组成)
      - [1.1.4.1. 计算机组成](#1141-计算机组成)
      - [1.1.4.2. 子系统互连](#1142-子系统互连)
      - [1.1.4.3. 程序执行](#1143-程序执行)
      - [1.1.4.4. 计算机体系结构](#1144-计算机体系结构)
    - [1.1.5. 程序设计语言](#115-程序设计语言)
      - [1.1.5.1. 计算机语言](#1151-计算机语言)
      - [1.1.5.2. 编程模式](#1152-编程模式)
    - [1.1.6. 软件工程](#116-软件工程)
      - [1.1.6.1. 开发过程模型](#1161-开发过程模型)
      - [1.1.6.2. 分析阶段](#1162-分析阶段)
      - [1.1.6.3. 设计阶段](#1163-设计阶段)
      - [1.1.6.4. 实现阶段](#1164-实现阶段)
      - [1.1.6.5. 测试阶段](#1165-测试阶段)
      - [1.1.6.6. 文档](#1166-文档)
    - [1.1.7. 数据结构](#117-数据结构)
    - [1.1.8. 抽象数据类型](#118-抽象数据类型)
    - [1.1.9. 文件结构](#119-文件结构)
    - [1.1.10. 数据库](#1110-数据库)
    - [1.1.11. 数据压缩](#1111-数据压缩)
    - [1.1.12. 安全](#1112-安全)
  - [1.2. 编译原理](#12-编译原理)
  - [1.3. 操作系统](#13-操作系统)
    - [1.3.1. 操作系统基本概念](#131-操作系统基本概念)
      - [1.3.1.1. 操作系统的功能](#1311-操作系统的功能)
      - [1.3.1.2. 操作系统发展过程](#1312-操作系统发展过程)
      - [1.3.1.3. 操作系统的特性](#1313-操作系统的特性)
      - [1.3.1.4. 操作系统的体系结构](#1314-操作系统的体系结构)
        - [1.3.1.4.1. 层次结构](#13141-层次结构)
        - [1.3.1.4.2. 微内核结构](#13142-微内核结构)
        - [1.3.1.4.3. 基本特性](#13143-基本特性)
    - [1.3.2. Linux基础](#132-linux基础)
      - [1.3.2.1. Linux各目录及每个目录的详细介绍](#1321-linux各目录及每个目录的详细介绍)
      - [1.3.2.2. Linux 和 UNIX 的关系/区别](#1322-linux-和-unix-的关系区别)
      - [1.3.2.3. Ｌinux版本](#1323-ｌinux版本)
        - [1.3.2.3.1. 常用的Linux发行版本族：](#13231-常用的linux发行版本族)
    - [1.3.3. 进程管理](#133-进程管理)
      - [1.3.3.1. 进程的基本概念](#1331-进程的基本概念)
      - [1.3.3.2. 进程控制](#1332-进程控制)
        - [1.3.3.2.1. 相关的Linux系统调用](#13321-相关的linux系统调用)
        - [1.3.3.2.2. fock原理](#13322-fock原理)
        - [1.3.3.2.3. 进程描述符和任务结构](#13323-进程描述符和任务结构)
      - [1.3.3.3. 进程同步](#1333-进程同步)
        - [1.3.3.3.1. 临界资源的概念](#13331-临界资源的概念)
        - [1.3.3.3.2. 进程的互斥与同步](#13332-进程的互斥与同步)
      - [1.3.3.4. 经典的进程同步问题](#1334-经典的进程同步问题)
    - [1.3.4. 进程通信](#134-进程通信)
      - [1.3.4.1. 管道](#1341-管道)
    - [1.3.5. 线程](#135-线程)
      - [1.3.5.1. 线程的基本概念](#1351-线程的基本概念)
      - [1.3.5.2. 多线程的实现](#1352-多线程的实现)
      - [1.3.5.3. 线程上下文](#1353-线程上下文)
      - [1.3.5.4. Linux进程和线程的区别](#1354-linux进程和线程的区别)
    - [1.3.6. 处理机调度和死锁](#136-处理机调度和死锁)
      - [1.3.6.1. 处理机调度的层次](#1361-处理机调度的层次)
      - [1.3.6.2. 进程调度](#1362-进程调度)
      - [1.3.6.3. 调度算法](#1363-调度算法)
        - [1.3.6.3.1. 优先级调度算法](#13631-优先级调度算法)
        - [1.3.6.3.2. 轮转调度算法](#13632-轮转调度算法)
      - [1.3.6.4. Linux的进程调度算法](#1364-linux的进程调度算法)
      - [1.3.6.5. 产生死锁的原因和必要条件](#1365-产生死锁的原因和必要条件)
    - [1.3.7. 存储器管理](#137-存储器管理)
      - [1.3.7.1. 存储器的层次结构](#1371-存储器的层次结构)
      - [1.3.7.2. 程序的装入和链接](#1372-程序的装入和链接)
      - [1.3.7.3. 连续分配方式](#1373-连续分配方式)
      - [1.3.7.4. 基本分段存储管理方式](#1374-基本分段存储管理方式)
      - [1.3.7.5. 虚拟存储器的基本概念](#1375-虚拟存储器的基本概念)
      - [1.3.7.6. 请求分页存储管理方式](#1376-请求分页存储管理方式)
      - [1.3.7.7. 页面置换算法](#1377-页面置换算法)
      - [1.3.7.8. 请求分段管理方式](#1378-请求分段管理方式)
    - [1.3.8. 设备管理](#138-设备管理)
      - [1.3.8.1. I/O系统](#1381-io系统)
      - [1.3.8.2. I/O控制方式](#1382-io控制方式)
      - [1.3.8.3. 缓冲管理](#1383-缓冲管理)
      - [1.3.8.4. I/O软件](#1384-io软件)
      - [1.3.8.5. 设备分配](#1385-设备分配)
      - [1.3.8.6. 磁盘存储器的管理](#1386-磁盘存储器的管理)
    - [1.3.9. 文件管理](#139-文件管理)
      - [1.3.9.1. 文件和文件系统](#1391-文件和文件系统)
      - [1.3.9.2. 文件的结构](#1392-文件的结构)
        - [1.3.9.2.1. 文件的逻辑结构](#13921-文件的逻辑结构)
        - [1.3.9.2.2. 文件的物理结构](#13922-文件的物理结构)
      - [1.3.9.3. 外存的分配方式](#1393-外存的分配方式)
      - [1.3.9.4. 目录管理](#1394-目录管理)
      - [1.3.9.5. 文件存储空间的管理](#1395-文件存储空间的管理)
      - [1.3.9.6. 文件共享与文件保护](#1396-文件共享与文件保护)
      - [1.3.9.7. 数据一致性控制](#1397-数据一致性控制)
    - [1.3.10. Ｌinux网络基础](#1310-ｌinux网络基础)
      - [1.3.10.1. 网络配置文件](#13101-网络配置文件)
    - [1.3.11. 系统安全性](#1311-系统安全性)
    - [1.3.12. Unix系统内核结构](#1312-unix系统内核结构)
  - [1.4. Linux系统编程](#14-linux系统编程)
    - [1.4.1. 标准](#141-标准)
      - [1.4.1.1. POSIX](#1411-posix)
      - [1.4.1.2. Sytem V](#1412-sytem-v)
      - [1.4.1.3. 使用](#1413-使用)
    - [1.4.2. 基本概念](#142-基本概念)
      - [1.4.2.1. 操作系统的核心](#1421-操作系统的核心)
      - [1.4.2.2. shell](#1422-shell)
      - [1.4.2.3. 用户和组](#1423-用户和组)
      - [1.4.2.4. 单根目录层级，目录，链接以及文件](#1424-单根目录层级目录链接以及文件)
      - [1.4.2.5. 文件IO模型](#1425-文件io模型)
      - [1.4.2.6. 程序](#1426-程序)
      - [1.4.2.7. 进程](#1427-进程)
      - [1.4.2.8. 内存映射](#1428-内存映射)
      - [1.4.2.9. 静态库和共享库](#1429-静态库和共享库)
      - [1.4.2.10. 进程间通信和同步](#14210-进程间通信和同步)
      - [1.4.2.11. 信号](#14211-信号)
      - [1.4.2.12. 线程](#14212-线程)
      - [1.4.2.13. 进程组和shell任务控制](#14213-进程组和shell任务控制)
      - [1.4.2.14. 会话，控制终端和控制进程](#14214-会话控制终端和控制进程)
      - [1.4.2.15. 伪终端](#14215-伪终端)
      - [1.4.2.16. 日期和时间](#14216-日期和时间)
      - [1.4.2.17. 客户端服务器架构](#14217-客户端服务器架构)
      - [1.4.2.18. 实时性](#14218-实时性)
      - [1.4.2.19. ／proc文件系统](#14219-proc文件系统)
  - [1.5. Unix环境编程](#15-unix环境编程)
    - [1.5.1. 基本概念](#151-基本概念)
    - [1.5.2. IO模型](#152-io模型)
    - [1.5.3. select&poll&epoll比较](#153-selectpollepoll比较)
      - [1.5.3.1. 整体概览](#1531-整体概览)
      - [1.5.3.2. 对比总结](#1532-对比总结)

<!-- /TOC -->


# 1. 计算机&网络&操作系统
<a href="#menu" >目录</a>

## 1.1. 计算机基础

<a href="#menu" >目录</a>

### 1.1.1. 数字系统
<a href="#menu" >目录</a>

**整数**

非实数:


$\pm S_{k-1} * 10^{k-1} + S_{k-2} * 10^{k-2}... S_{1} * 10^{1} + S_{0} * 10^{0}$ 

$1234 = 1*10^3 + 2*10^2 + 3*10^1+ 4*10^0$

实数:
$\pm S_{k-1} * 10^{k-1} + S_{k-2} * 10^{k-2}... S_{1} * 10^{1} + S_{0} * 10^{0}$ 



**实数**

**二进制**

**八进制**


**十六进制**


#### 1.1.1.1. ASCII
* ASCII控制字符

|二进制|	十进制|	十六进制	|缩写	|名称/意义|
|---|---|---|---|---|
|0000 0000	|0	|00	|NUL	|空字符（Null）
|0000 0001	|1	|01	|SOH		|标题开始
|0000 0010	|2	|02	|STX	  |本文开始
|0000 0011	|3	|03	|ETX		|本文结束
|0000 0100	|4	|04	|EOT		|传输结束
|0000 0101	|5	|05	|ENQ		|请求
|0000 0110	|6	|06	|ACK		|确认回应
|0000 0111	|7	|07	|BEL		|响铃
|0000 1000	|8	|08	|BS	|退格
|0000 1001	|9	|09	|HT		|水平定位符号
|0000 1010	|10	|0A	|LF		|换行键
|0000 1011	|11	||0B	|VT	|垂直定位符号
|0000 1100	|12	|0C	|FF		|换页键
|0000 1101	|13	|0D	|CR		|归位键
|0000 1110	|14	|0E	|SO		|取消变换（Shift out）
|0000 1111	|15	|0F	|SI		|启用变换（Shift in）
|0001 0000	|16	|10	|DLE		|跳出数据通讯
|0001 0001	|17	|11	|DC1		|设备控制一（XON 启用软件速度控制）
|0001 0010	|18	|12	|DC2		|设备控制二
|0001 0011	|19	|13	|DC3		|设备控制三（XOFF 停用软件速度控制）
|0001 0100	|20	|14	|DC4		|设备控制四
|0001 0101	|21	|15	|NAK		|确认失败回应
|0001 0110	|22	|16	|SYN		|同步用暂停
|0001 0111	|23	|17	|ETB		|区块传输结束
|0001 1000	|24	|18	|CAN		|取消
|0001 1001	|25	|19	|EM		|连接介质中断
|0001 1010	|26	|1A	|SUB		|替换
|0001 1011	|27	|1B	|ESC		|跳出
|0001 1100	|28	|1C	|FS		|文件分割符
|0001 1101	|29	|1D	|GS	|组群分隔符
|0001 1110	|30	|1E	|RS		|记录分隔符
|0001 1111	|31	|1F	|US		|单元分隔符
|0111 1111	|127	|7F	|DEL	|删除

* ASCII可显示字符

|二进制	|十进制	|十六进制	|图形|
|---|---|---|---|
|0010 0000|	32|	20|	（空格）(␠)
|0010 0001|	33|	21	|!
|0010 0010|	34|	22	|"
|0010 0011|	35|	23	|#
|0010 0100|	36|	24|	$
|0010 0101|	37|	25|	 %
|0010 0110|	38|	26|	&
|0010 0111|	39|	27|	'
|0010 1000|	40|	28|	(
|0010 1001|	41|	29|	)
|0010 1010|	42|	2A|	*
|0010 1011|	43|	2B|	+
|0010 1100|	44|	2C|	,
|0010 1101|	45|	2D|	-
|0010 1110|	46|	2E|	.
|0010 1111|	47|	2F|	/
|0011 0000|	48|	30|	0
|0011 0001|	49|	31|	1
|0011 0010|	50|	32|	2
|0011 0011|	51|	33|	3
|0011 0100|	52|	34|	4
|0011 0101|	53|	35|	5
|0011 0110|	54|	36|	6
|0011 0111|	55|	37|	7
|0011 1000|	56|	38|	8
|0011 1001|	57|	39|	9
|0011 1010|	58|	3A|	:
|0011 1011|	59|	3B|	;
|0011 1100|	60|	3C|	<
|0011 1101|	61|	3D|	=
|0011 1110|	62|	3E|	>
|0011 1111|	63|	3F|	?
|0100 0000|	64|	40	|@
|0100 0001|	65|	41	|A
|0100 0010|	66|	42	|B
|0100 0011|	67|	43	|C
|0100 0100|	68|	44	|D
|0100 0101|	69|	45	|E
|0100 0110|	70|	46	|F
|0100 0111|	71|	47	|G
|0100 1000|	72|	48	|H
|0100 1001|	73|	49	|I
|0100 1010|	74|	4A	|J
|0100 1011|	75|	4B	|K
|0100 1100|	76|	4C	|L
|0100 1101|	77|	4D	|M
|0100 1110|	78|   4E	|N
|0100 1111|	79|	4F|	O
|0101 0000|	80|	50	|P
|0101 0001|	81|	51	|Q
|0101 0010|	82|	52	|R
|0101 0011|	83|	53	|S
|0101 0100|	84|	54	|T
|0101 0101|	85|	55	|U
|0101 0110|	86|	56	|V
|0101 0111|	87|	57	|W
|0101 1000|	88|	58	|X
|0101 1001|	89|	59	|Y
|0101 1010|	90|	5A	|Z
|0101 1011|	91|	5B	|[
|0101 1100|	92|	5C	|\
|0101 1101|	93|	5D	|]
|0101 1110|	94|	5E	|^
|0101 1111|	95|	5F	|_
|0110 0000|	96|	60	|`
|0110 0001|	97|	61	|a
|0110 0010|	98|	62	|b
|0110 0011|	99|	63	|c
|0110 0100|	100|	64	|d
|0110 0101|	101| 65	|e
|0110 0110|	102|	66	|f
|0110 0111|	103|	67	|g
|0110 1000|	104|	68	|h
|0110 1001|	105|	69	|i
|0110 1010|	106|	6A	|j
|0110 1011|	107|	6B	|k
|0110 1100|	108|	6C	|l
|0110 1101|	109|	6D	|m
|0110 1110|	110|	6E	|n
|0110 1111|	111|	6F	|o
|0111 0000|	112|	70	|p
|0111 0001|	113|	71	|q
|0111 0010|	114|	72	|r
|0111 0011|	115|	73	|s
|0111 0100|	116|	74	|t
|0111 0101|	117|	75	|u
|0111 0110|	118|	76	|v
|0111 0111|	119|	77	|w
|0111 1000|	120|	78	|x
|0111 1001|	121|	79	|y
|0111 1010|	122|	7A	|z
|0111 1011|	123|	7B	|{
|0111 1100|	124|	7C	|\|
|0111 1101|	125|	7D	|}
|0111 1110|	126|	7E	|~

### 1.1.2. 数据存储
<a href="#menu" >目录</a>

### 1.1.3. 数据运算
<a href="#menu" >目录</a>

### 1.1.4. 计算机组成
<a href="#menu" >目录</a>

#### 1.1.4.1. 计算机组成

* 中央处理器CPU
    * 作用
        * 用于数据的运算
    * 三大部分
        * 算术逻辑单元
            * 对数据进行逻辑,移位,和算术运算
        * 寄存器
            * 用来存放临时数据的高速独立的存储单元
            * 数据寄存器
                * 用来存储输入数据和运算结果,可以提高运算速度
            * 指令寄存器
                * CPU的主要职责就是从内存中逐条取出指令,并将指令存储在指令寄存器中,解释并执行
            * 程序计数器
                * 保存当前正在执行的指令,当前指令执行完后,计数器将自动加1,指向下一条指令的内存地址
        * 控制单元
            * 控制各个子系统的操作
* 主存储器
    * 存储单元的集合,每一个存储单元都有唯一的标识,也就是地址
    * 存储器类型
        * 随机存取存储器RAM
            * 数据断电会丢失
            * SRAM
                * 技术是使用传统的触发器门电路
                * 速度较快,价格较贵                                                                                                                                                                                                                                   
            * DRAM
                * 使用电容器
                * 速度较慢,价格较便宜
        * 只读存储器ROM
            * 只能读不能写,断电数据不丢失,一般用来存储程序或者数据
        * 可编程只读存储器PROM
        * 可擦除可编程存储器EPROM
            * 用户可以对它进行编程,需要一种可以发出紫外光的特殊仪器进行擦写
        * 电可擦除可编程存储器EEPROM
            * 对它的编程和擦除都是使用电子脉冲即可,无需从计算机上拆除下来
* 输入/输出子系统

#### 1.1.4.2. 子系统互连

**CPU和存储器的连接**

CPU和存储器一般使用三组线进行连接:数据总线,控制总线,地址总线

* 数据总线
    * 每一根线上传送一位数据,线的数量取决于计算机字的大小,比如32位的计算机需要32根线的数据总线,以便一次传输完一个字的数据
* 地址总线
    * 地址总线的线数取决于存储空间的大小,存储器容量为2^N,就需要N根线
* 控制总线
    * 控制读写时钟等操作

**输入输出设备寻址**

* I/O独立寻址
    * 用来读写内存的指令和用来读写输入输出设备的指令不同,有专门的指令完成对输入输出设备的读写控制等操作
* I/O存储器的映射寻址
    * 用来读写内存的指令和用来读写输入输出设备的指令相同,CPU将输入/输出控制器中的每一个寄存器都看作内存中的某个存储字

#### 1.1.4.3. 程序执行

* 机器周期
    * 取指令
        * 控制单元命令系统将下一条将要执行的指令复制到CPU的指令寄存器.被复制的指令地址保存在程序计数器中.复制完成后,程序计数器自动加1指向内存中的下一条指令
    * 译码
        * 当指令置于指令寄存器后,该指令将由控制单元负责译码,指令译码的结果就是系统可以识别执行的二进制代码
    * 执行
        * 译码完成后,控制单元发送任务命令到CPU的某个部件执行

#### 1.1.4.4. 计算机体系结构

* 复杂指令集计算机CISC(complex instruction set computer)
    * 指令多且复杂
    * 使得CPU和控制单元的电路非常复杂
* 精简指令集计算机RISC(reduce instruction set computer)
    * 使用少量的指令完成最少的操作,复杂指令使用简单指令集模拟



### 1.1.5. 程序设计语言
<a href="#menu" >目录</a>

#### 1.1.5.1. 计算机语言

* 计算机语言
    * 根据事先定义的规则(语法)而写出的预定语句的语句集合
    * 机器语言
        * 机器语言是计算机硬件唯一能理解的语言
        * 由"0"\"1"组成,表示两种电子开关的状态
    * 汇编语言
        * 带符号和助记符的指令和地址代替机器语言的二进制码
        * 难于理解,编程复杂
    * 高级语言
        * 比如C/C++,Java等
        * 高级语言转化为机器语言的过程为解释或者编译

* 高级语言翻译为机器语言
    * 编译
        * 把整个源程序翻译成目标程序
    * 解释
        * 把源程序中的每一行翻译成目标程序中相应的行,并执行它的过程
        * 早期的解释式语言BASIC|APL
            * 源程序的每一行被翻译成其计算机上的机器语言,该行机器语言被立即执行,如果在翻译和执行的过程中有任何错误,过程就会被终止.
        * Java所使用的
            * 源程序到目标程序两个阶段:编译和解释
            * 源程序先经过编译成虚拟机可识别的字节码,然后能被任何运行JVM模拟器的计算机编译或者解释

编译和解释不同在于:编译在执行前翻译整个源代码,而解释一次只翻译和执行源代码中的一行.两种方法都遵循如下的翻译过程
```
源文件---符号--->词法分析器---助记符--->语法分析器---指令--->语义分析器---可编码的指令--->代码生成器---代码--->目标文件
```
* 词法分析器
    * 语法分析器一个符号一个符地读源代码,创建源代码中的助助记符,比如'f''o''r'被读入,就成了高级语言中的助记符"for"
* 语法分析器
    * 分析助记符,找出指令
* 语义分析器
    * 检查分析器创建的句子,确保不会有二义性
* 代码生成器
    * 在无二义性指令被创建完成后,每条指令将转化成计算机的机器语言

#### 1.1.5.2. 编程模式

* 面向过程
* 面向对象
* 函数式
* 声明式

### 1.1.6. 软件工程
<a href="#menu" >目录</a>

#### 1.1.6.1. 开发过程模型

* 瀑布模型
    * 开发过程只有一个阶段,前一个阶段不结束,后一个阶段不能开始(分析-设计-实现-测试)
    * 优点:下一个阶段开始前每个阶段已经完成
    * 缺点:难以定位问题,如果过程的一部分有问题,那么必须检视整个过程
* 增量模型
    * 先完成整个系统的简化版本,后续增加实现各个细节,直到所有得到要求全部实现

#### 1.1.6.2. 分析阶段

* 面向过程分析
    * 常用建模工具
        * 数据视图
            * 显示系统中数据的流动
        * 实体关系图
        * 状态图
* 面向对象分析
    * 用例图
    * 类图
    * 状态图

#### 1.1.6.3. 设计阶段

* 面向过程设计
    * 结构图,描述模块间的关系
    * 模块化,降低耦合和提高内聚
        * 耦合:两个模块间互相绑定程度的度量,耦合越大,独立性越差.修改一个模块时可能会影响另一个模块
        * 内聚:程序中处理过程相关紧密程度的度量
         
* 面向对象设计
    * 详细描述类的实现细节
* 语言的选择

#### 1.1.6.4. 实现阶段

* 软件质量
    * 可操作性
        * 准确性
            * 准确性可以通过故障平均时间,每千行代码错误数等来度量
        * 高效性
            * 也就是性能
        * 可靠性
            * 故障率,故障平均时间
        * 安全
        * 及时性
        * 适用性
    * 可维护性
    * 可迁移性

#### 1.1.6.5. 测试阶段

* 白盒测试
    * 基于知道软件内部结构进行测试,测试的目标是检查软件所有的部分是否全部设计出来
    * 完成白盒测试需要保证
        * 每个模块中的所有独立的路径至少被测试过一次
        * 所有的判断结构每个分支都要进行测试
        * 每个循环被测试
        * 所有的数据结构都被测试
    * 测试方法
        * 基本路径测试
            * 软件中的每条语句必须被执行一次
        * 控制结构测试
            

* 黑盒测试
    * 不知道程序内部如何工作的情况下进行测试
    * 穷尽测试
        * 用输入域中的所有可能的值区测试软件,效率偏低
    * 随机测试
    * 边界值测试

#### 1.1.6.6. 文档

* 用户文档
    * 软件使用手册
* 系统文档
* 技术文档

### 1.1.7. 数据结构
<a href="#menu" >目录</a>

### 1.1.8. 抽象数据类型
<a href="#menu" >目录</a>

### 1.1.9. 文件结构
<a href="#menu" >目录</a>

### 1.1.10. 数据库
<a href="#menu" >目录</a>

### 1.1.11. 数据压缩
<a href="#menu" >目录</a>

### 1.1.12. 安全
<a href="#menu" >目录</a>


## 1.2. 编译原理
<a href="#menu" >目录</a>



## 1.3. 操作系统
<a href="#menu" >目录</a>

计算机系统由软件和硬件组成,硬件是计算机系统的基础,操作系统是位于硬件上的第一层软件,用于控制管理各种硬件资源.为其他软件和用户提供了工作环境.操作系统为人们有效的使用计算机提供了用户接口.操作系统还要对系统资源进行统一管理,使各并发进程能改按照一定的原则合理共享计算机资源,并在保证各个并发进程顺利运行的基础上提高资源的利用率,操作系统是整个计算机的控制管理中心.

### 1.3.1. 操作系统基本概念
<a href="#menu" >目录</a>

#### 1.3.1.1. 操作系统的功能
<a href="#menu" >目录</a>

**1.提供人机接口**
* 作业控制级接口
* 程序级接口

**管理计算机资源**
* 进程管理
    * 进程调度
    * 进程通信
    * 进程控制
    * 进程同步
* 存储管理
    * 内存分配
    * 地址转换
    * 内存保护
    * 内存扩充
* 设备管理
    * 设备分配
    * 缓冲管理
    * 设备驱动
    * 设备独立性
* 文件管理
    * 文件存储空间的管理
    * 目录管理
    * 文件操作
    * 文件的存取和权限管理
    

#### 1.3.1.2. 操作系统发展过程

* 无操作系统的计算机
* 单道批处理系统
* 分时系统
* 实时系统

#### 1.3.1.3. 操作系统的特性

* 程序并发运行
    * 宏观上多道程序同时运行,微观上交替运行,如果有多个CPU,可以实现并行
    * 提高资源利用率和系统吞吐量
    * 由操作系统实现并发的管理
* 资源共享
    * 共享的理由
        * 各用户或任务独占系统资源将导致资源浪费
        * 多个任务共享一个程序的同一个副本
* 异步
* 虚拟
    * 虚拟指的是通过某种技术把一个物理实体映射为多个逻辑实体,用户程序使用的是逻辑实体
    * 比如虚拟内存,docker的应用

#### 1.3.1.4. 操作系统的体系结构

##### 1.3.1.4.1. 层次结构

##### 1.3.1.4.2. 微内核结构



##### 1.3.1.4.3. 基本特性

### 1.3.2. Linux基础


#### 1.3.2.1. Linux各目录及每个目录的详细介绍

```
/ 虚拟目录的根目录。通常不会在这里存储文件
/bin 二进制目录，存放许多用户级的GNU工具
/boot 启动目录，存放启动文件
/dev 设备目录， Linux在这里创建设备节点
/etc 系统配置文件目录
/home 主目录， Linux在这里创建用户目录
/lib 库目录，存放系统和应用程序的库文件
/media 媒体目录，可移动媒体设备的常用挂载点
/mnt 挂载目录，另一个可移动媒体设备的常用挂载点
/opt 可选目录，常用于存放第三方软件包和数据文件
/proc 进程目录，存放现有硬件及当前进程的相关信息
/root root用户的主目录
/sbin 系统二进制目录，存放许多GNU管理员级工具
/run 运行目录，存放系统运作时的运行时数据
/srv 服务目录，存放本地服务的相关文件
/sys 系统目录，存放系统硬件信息的相关文件
/tmp 临时目录，可以在该目录中创建和删除临时工作文件
/usr 用户二进制目录，大量用户级的GNU工具和数据文件都存储在这里
/var 可变目录，用以存放经常变化的文件，比如日志文件

/usr 最庞大的目录，要用到的应用程序和文件几乎都在这个目录，其中包含：

/usr/x11R6 存放x window的目录
/usr/bin 众多的应用程序
/usr/sbin 超级用户的一些管理程序
/usr/doc linux文档
/usr/include linux下开发和编译应用程序所需要的头文件
/usr/lib 常用的动态链接库和软件包的配置文件
/usr/man 帮助文档
/usr/src 源代码，linux内核的源代码就放在/usr/src/linux里
/usr/local/bin 本地增加的命令
/usr/local/lib 本地增加的库根文件系统
```

#### 1.3.2.2. Linux 和 UNIX 的关系/区别

Linux 是一个类似 Unix 的操作系统，Unix 要早于 Linux，Linux 的初衷就是要替代 UNIX，并在功能和用户体验上进行优化，所以 Linux 模仿了 UNIX（但并没有抄袭 UNIX 的源码），使得 Linux 在外观和交互上与 UNIX 非常类似。
说模仿可能会被人喷，你也可以说微创新或者改进。
相比于 UNIX，Linux 最大的创新是开源免费，这是它能够蓬勃发展的最重要原因；而目前的 UNIX 大部分都是收费的，小公司和个人都难以承受。

正是由于 Linux 和 UNIX 有着千丝万缕的联系，所以人们把 Linux 叫做“类UNIX系统”

UNIX/Linux 系统可以粗糙地抽象为 3 个层次.底层是 UNIX/Linux 操作系统，即系统内核（Kernel）；中间层是 Shell 层，即命令解释层；高层则是应用层．

* 内核层
    * 内核层是 UNIX/Linux 系统的核心和基础，它直接附着在硬件平台之上，控制和管理系统内各种资源（硬件资源和软件资源），有效地组织进程的运行，从而扩展硬件的功能，提高资源的利用效率，为用户提供方便、高效、安全、可靠的应用环境。
* Shell层
    * Shell 层是与用户直接交互的界面。用户可以在提示符下输入命令行，由 Shell 解释执行并输出相应结果或者有关信息，所以我们也把 Shell 称作命令解释器，利用系统提供的丰富命令可以快捷而简便地完成许多工作。
* 应用层
    * 应用层提供基于 X Window 协议的图形环境。X Window 协议定义了一个系统所必须具备的功能（就如同 TCP/IP 是一个协议，定义软件所应具备的功能），可系统能满足此协议及符合 X 协会其他的规范，便可称为 X Window。

* X Window 与微软的 Windows 图形环境有很大的区别：
    * UNIX/Linux 系统与 X Window 没有必然捆绑的关系，也就是说，UNIX/Linux 可以安装 X Window，也可以不安装；而微软的 Windows 图形环境与内核捆绑密切。
    * UNIX/Linux 系统不依赖图形环境，依然可以通过命令行完成 100% 的功能，而且因为不使用图形环境还会节省大量的系统资源。

作为服务器部署，绝大多数 Linux 并不安装或并不启用图形环境

#### 1.3.2.3. Ｌinux版本

* Linux内核版本与linux发行版本的区别：LINUX内核版本是指系统内核的版本号，LINUX的内核具有两种不同的版本号，实验版本和产品化版本。首先解释一下什么是Linux发行版(英文名称是Linux Distribution)。Linux实际上是一种开放源代码的操作系统内核，通常我们说的Linux指的是基于Linux内核的操作系统。
* Linux操作系统包括Linux内核和Linux用户态程序，Linux内核和Linux用户态程序都是开放源代码的，绝大多数软件代码遵循GPL协议，任何人拿到这些代码都可以对这些代码进行修改和分发。
* 由于Linux上代码的高度自由，很多公司和组织都推出了自己的Linux操作系统，这些Linux操作系统我们就叫做Linux发行版。各种不同的Linux发行版的共同点就是都使用了Linux内核，不同的Linux发行版的内核可能有一些小的修改。
* 要确定 LINUX版本 的类型，只要查看一下版本号：每一个版本号由三位数字组成，第二位数字说明版本类型。如果第二位数字是偶数则说明这种版本是产品化版本，如果是奇数说明是实验版本。
如2.4.18是产品化版本，2.5.21是实验版本。查看 linux内核版本 命令：uname -r Linux发行版本 是指一些 Linux厂商 将 LINUX系统内核 与应用软件及文档包装在一起，并提供一些安装界面和系统设定与管理工具，这就构成了一个发行套件。

**查看Linux版本**
```
1、# uname －a （Linux查看版本当前操作系统内核信息）
2、# cat /proc/version （Linux查看当前操作系统版本信息）
3、# cat /etc/issue 或 cat /etc/redhat-release （Linux查看版本当前操作系统发行版信息）
4、# cat /proc/cpuinfo （Linux查看cpu相关信息，包括型号、主频、内核信息等）
5、# getconf LONG_BIT （Linux查看版本多少位）
6、# lsb_release -a （CentOS 6.9版本需要安装lsb，CentOS 7.0以上直接可以使用，网上都说Linux都支持，我只验证过CentOS系统）
```

##### 1.3.2.3.1. 常用的Linux发行版本族：

**redhat家族**

主要包括有redhat 企业版，CentOS版本，Fedara

redhat 企业版，这个需要授权费，主要用在高要求的服务器商用系统，比如各种运营商内部非核心系统，在版本上注重了性能和稳定性以及对硬件的支持。 由于企业版操作系统的开发周期较长，注重性能、稳定性和服务端软件支持，因此版本更新相对较缓慢。

CentOS：CentOS全名为“社区企业操作系统”，CentOS社区将Red hat的网站上的所有源代码下载下来，进行重新编译。由于AS/ES/WS是商业产品，因此，必须将所有Red hat的Logo和标识改成自己的CentOS标识。比如将AS4。0原版的SRPM源码编译后，换上Centos社区的logo，这样就成为了CentOS 4.0。Redhat Enterprise Linux AS4 Update1的源码编译后，就成为了CentOS4.1。AS4 Update2的源码编译后，就成为了CentOS4.2等等。CentOS就是这样产生的。此版本主要用在互联网各大中小网站。

Fedara：被红帽公司定位为新技术的实验场地，许多新的技术都会在 FC 中检验，如果稳定的话红帽公司则会考虑加入 Red Hat Enterprise Linux 中;一般在服务器上不推荐采用Fedora Core。其实可以这么认为，Fedora就是Red Hat发行Red Hat企业版Linux的一个实验版本，拿用户做测试，为Red Hat企业版发布做基础。

还有其它版本如下：Scientific Linux/Oracle Linux

**Debian**

Debian运行起来极其稳定，这使得它非常适合用于服务器。Debian平时维护三套正式的软件库和一套非免费软件库，这给另外几款发行版（比如Ubuntu和Kali等）带来了灵感。Debian这款操作系统派生出了多个Linux发行版。它有37500多个软件包，这方面唯一胜过Debian的其他发行版只有Gentoo。Debian使用apt或aptitude来安装和更新软件。

Debian这款操作系统无疑并不适合新手用户，而是适合系统管理员和高级用户。Debian支持如今的大多数架构（处理器）。

主要基于Debian的版本如下：Debian/Ubuntu/Linux Mint/Knoppix/MEPIS/sidux/CrunchBang Linux/Chromium OS/Google Chrome OS

重点推荐：Ubuntu是Debian的一款衍生版，也是当今最受欢迎的免费操作系统,是一个以桌面应用为主的Linux操作系统,Ubuntu的目标在于为一般用户提供一个最新的、同时又相当稳定的主要由自由软件构建而成的操作系统。Ubuntu具有庞大的社区力量，用户可以方便地从社区获得帮助。2013年1月3日，Ubuntu正式发布面向智能手机的移动操作系统。笔者现在也在使用此版本。

**SUSE**

是欧洲大陆最流行的LINUX起源于德国，于2003年末被Novell收购。主要版本有：SUSE Linux，针对个人用户，可以免费下载；

另一个是SUSE Linux Enterprise Server (SLES)是基于企业服务器端的。如果需要使用数据库高级服务和电子邮件网络应用可以选SUSE

主要版本：SUSE Linux Enterprise Server (SLES) 最新版本SUSE Linux Enterprise 12/SUSE Linux Enterprise Desktop（SLED）/SUSE Manager （版本号1.7）/SUSE Studio

**Gentoo**

是Linux世界最年轻的发行版本，正因为年轻，所以能吸取在她之前的所有发行版本的优点。Gentoo最初由Daniel Robbins（FreeBSD的开发者之一）创建，首个稳定版本发布于2002年。由于开发者对FreeBSD的熟识，所以Gentoo拥有媲美FreeBSD的广受美誉的ports系统——Portage包管理系统。不同于APT和YUM等二进制文件分发的包管理系统，Portage是基于源代码分发的，必须编译后才能运行，对于大型软件而言比较慢，不过正因为所有软件都是在本地机器编译的，在经过各种定制的编译参数优化后，能将机器的硬件性能发挥到极致。Gentoo是所有Linux发行版本里安装最复杂的，但是又是安装完成后最便于管理的版本，也是在相同硬件环境下运行最快的版本.

相关版本：Gentoo Linux/Sabayon Linux/Calculate Linux/Funtoo Linux/


### 1.3.3. 进程管理
<a href="#menu" >目录</a>

#### 1.3.3.1. 进程的基本概念
<a href="#menu" >目录</a>

进程是操作系统中一个非常重要的概念,程序的运行是通过进程来完成的.在层次结构的操作系统中.进程不仅使系统分配资源的基本单位.而且是CPU调度的基本单位.

Unix系统中,进程的创建通过函数fork进行创建,这个系统调用会创建一个与调用进程相同的副本.在调用fork之后,这两个进程(父进程和子进程)拥有相同的内存映像,相同的环境字符串和相同的打开文件.但是父子进程却拥有各自独立的地址空间.如果其中某一个进程在其地址空间修改了一个字,则这一改变对另一个进程是不可见的.子进程的初始地址是父进程地址空间的一个副本,但是这是两个不同的地址空间,可写的地址空间是不共享的.但是,一个新建的进程可能共享像打开文件之类的资源.

进程就是处于执行期的程序，但是进程不仅仅局限于一段打开的可执行程序代码(unix称其为代码段，text section)，通常进程还包含其他资源，像打开的文件，挂起的信号，内核内部数据，处理器状态，一个或者多个具有内存映射的内存地址空间以及一个或者多个执行的线程，当然还包括存放全局变量的数据段等。

线程是进程中活动的对象，每一个进程都拥有一个独立的程序计数器，进程栈和一组进程寄存器，内核调度的对象是线程，而不是进程。

在现代操作系统中，进程


* 进程和程序的区别
    * 程序是静态的概念,本身可以作为一种软件资源长期保存,而进程是程序的一次执行过程,是动态的概念
    * 进程是一个能独立运行的单位,能与其他进程并发执行.进程作为资源申请和调度单位存在.通常程序不能作为一个独立运行的单位而并发执行
    * 程序和进程不存在一一对应的关系,一个程序可由多个进程共用,一个进程在其活动中又可顺序执行若干个程序
    * 各个进程在并发执行过程中会产生相互制约的关系,造成各自前进速度的不可预测性,而程序本身是静态的,不存在这种异步特征.

* 进程的特征
    * 动态性
        * 进程是程序的执行过程
    * 并发性
        * 同一个计算机上的进程会存在并发执行的情况
    * 独立性
        * 进程是一个能独立运行的基本单位,是系统中独立获得资源和独立调度的基本单位
    * 异步性

* 进程的终止
    * 正常退出
    * 出错退出
    * 严重错误
    * 被其他进程杀死

* 进程的层次结构
    * 进程创建子进程之后,子进程也可以创建子进程,这些进程共同组成一个进程组
    * 如果一个信号(比如kill)发送给一个进程组,那么每个进程都可以捕获这个信号,忽略该信号或者采取默认的动作


* 进程的状态
    * 运行态
        * 获得CPU的运行权,正在运行
        * 单CPU计算机同一时刻只能有一个进程处于执行状态
    * 就绪态
        * 进程的外部条件满足,但是因为其他进程已经占用CPU,所以暂时不能运行
    * 阻塞态
        * 进程正在等待某种事件发生而暂时不能运行起来

#### 1.3.3.2. 进程控制
<a href="#menu" >目录</a>

进程控制就是系统使用一个引起具有特定功能的程序段来创建,撤销进程以及完成进程各状态间的转换,从而达到多进程高效率并发执行和协调,实现资源共享的目的.通常,把系统态下执行的某些具有特定功能的程序段成为原语(原子操作).原语可以分为两类,一类是机器指令级的,执行期间不允许中断.一类是功能级的,其特点是作为原语的程序段不允许并发执行.这两类原语都是在系统态下执行,都是为了完成某个系统管理锁需要的功能而被高层软件所调用.

##### 1.3.3.2.1. 相关的Linux系统调用

**fork系统调用**
```c
//创建一个进程,返回值为pid
int fork();
```

* pid=0:创建子进程成功,表示从子进程返回
* pid>0:创建子进程成功,表示从父进程返回,pid的值为新创建的子进程标识号
* pid=-1:子进程创建失败

```c
     
#include "stdio.h"
#include "unistd.h"

int main(){

    printf("hello!my pid is %d\r\n",getpid());
    
    int count = 0;
    int pid = fork();
    if(pid < 0){
        printf("create process error!\r\n");

    }   
    else if(pid == 0){
        //处理子进程业务
        printf("I am child proccess ,my pid is : %d\r\n",getpid());
        count++;
        printf("child process:count = %d\r\n",count);
    }
   
    else{
        //处理父进程业务
        printf("I am main  proccess ,my pid is : %d\r\n",getpid());
        count++;
        printf("main process:count = %d\r\n",count);
    }

   

}

//执行输出
lgj@lgj-Lenovo-G470:~/aProject/c$ ./hello
hello!my pid is 7512
I am main  proccess ,my pid is : 7512
main process:count = 1
I am child proccess ,my pid is : 7513
child process:count = 1

```

**exec()系统调用**

exec()用于执行新的程序

**exit()系统调用**
实现进程的自我终止

**wait()系统调用**

该系统调用将调用进程挂起,直至其子进程因暂停或终止而发来软中断信号为止.

##### 1.3.3.2.2. fock原理

```c
pid_t fock(void)
```
**返回值：**
pid_t 是进程描述符，实质就是一个int，如果fork函数调用失败，返回一个负数，调用成功则返回两个值：0和子进程ID。 

**函数功能：** 
以当前进程作为父进程创建出一个新的子进程，并且将父进程的所有资源拷贝给子进程，这样子进程作为父进程的一个副本存在。父子进程几乎时完全相同的，但也有不同的如父子进程ID不同。 

**需要注意的是：** 
当fork系统调用成功时，它会返回两个值：一个是0，另一个是所创建的新的子进程的ID（>0）。当fork成功调用后此时有两个数据相同的父子进程，我们可以通过fork的返回值来判断接下来程序是在执行父进程还是子进程。
* id==0：执行子进程
* id>0：在父进程中执行
* id<0：fork函数调用失败

fork()系统调用通过复制一个现有进程来创建一个全新的进程。进程被存放在一个叫做任务队列的双向循环链表当中，链表当中的每一项都是类型为task_struct称为进程描述符的结构，也就是进程PCB.

内核通过一个位置的进程标识值或PID来标识每一个进程。最大值默认为32768，short int短整型的最大值.他就是系统中允许同时存在的进程最大的数目。 可以到目录 /proc/sys/kernel中查看pid_max

当进程调用fork后，当控制转移到内核中的fork代码后，内核会做4件事情: 
1. 分配新的内存块和内核数据结构给子进程
2. 将父进程部分数据结构内容拷贝至子进程
3. 添加子进程到系统进程列表当中
4. fork返回，开始调度器调度 

##### 1.3.3.2.3. 进程描述符和任务结构
<a href="#menu" >目录</a>

内核把进程的列表存放在任务队列中(task list)的双向循环链表中，链表的每一项是类型为task_struct，称为进程描述符。该结构存放在include/linux/sched.h中。进程描述符包含了一个具体进程的所有信息。进程描述符中包含的数据能够完整地描述一个正在执行的程序：它打开的文件，挂起的信号，进程的状态等其他信息。该结构相对较大，32位机上大约有1.7kb。





#### 1.3.3.3. 进程同步
<a href="#menu" >目录</a>


##### 1.3.3.3.1. 临界资源的概念

在操作系统引入进程以及进程并发性概念之后,增加了系统的效率,同时由于资源有限导致了进程之间的资源竞争与共享.

* 临界资源
    * 两个或者两个以上的进程不能同时使用的资源称为临界资源.
    * 临界资源可以是一些独占设备,比如打印机,磁带机等,也可能是一些共享变量,表格,链表等

* 临界区
    * 不论硬件临界资源还是软件临界资源,多个进程必须互斥对其进行访问.每个进程访问临界资源的那段代码称为临界区(Critical Section).
    * 为了保证临界区的互斥访问,每次进程在进入临界区以前,应先对欲访问的临界资源进行检测,查看是否有其他进程正在访问
    * 因此需要在临界区之前增加检测代码(进入区),在退出临界区增加检查退出临界区的代码(退出区).

##### 1.3.3.3.2. 进程的互斥与同步

* 进程互斥
    * 多个进程不能同时使用同一个临界资源,也就是互斥访问
* 进程同步
    * 指有协作关系的进程之间不断地调整它们之间的相对速度或者执行过程,以保证临界资源的合理利用和进程的顺利执行.一般使用加锁操作,信号量等来解决
* 同步机制应遵循的规划
    * 空闲让进
        * 并发进程中的某个进程不在临界区时,不阻止其他进程进入临界区
    * 忙则等待
        * 临界区有其他进程在访问时,想要访问的进程必须等待
    * 有限等待
        * 应保证在一定的时间内访问到临界资源,避免死等
    * 让权等待
        * 当进程不能进入自己的临界区,应立即释放处理机,以避免进程陷入"忙等"状态
    
* 锁机制
    * 在临界区之前加锁,比如使用一个标志位.在临界区之后释放锁
    * 存在的问题:不断检测,直到其他进程释放锁.容易造成浪费时间.

* 信号量机制
    * wait
    * signal

#### 1.3.3.4. 经典的进程同步问题
<a href="#menu" >目录</a>


### 1.3.4. 进程通信
<a href="#menu" >目录</a>


* Unix系统提供的进程间通信的基本机制
    * 管道和FIFO(命名管道)
        * 最适合在进程之间实现生产者／消费者的交互．有些进程向管道中写入数据，而另外一些进程则从管道中读出数据
    * 信号量
        * 内核信号量的用户态版本
    * 消息
        * 允许进程在预定义的消息队列中读和写消息来交换信息．linux提供了两种消息版本：Ｓystem V IPC和posix消息
    * 共享内存区
        * 允许进程通过共享内存来交换信息
    * 套接字
        * 通过网络交换信息


* 低级通信
    * 进程间控制消息的交换,比如进程的互斥和同步以及信号量
* 高级通信
    * 进程间大量消息的交换
    * 实现方案
        * 共享存储系统
            * 共享存储器系统的类型
                * 基于共享数据结构的通信方式
                    * 各个进程共用某些数据结构,以实现各进程间的信息交换.效率低,只适用于传递相对少量的数据
                * 基于共享存储区的通信方式
                    * 各个进程通过访问共享存储区的数据读或者写来实现通信 
        * 消息传递系统
        * 管道通信系统
            * 管道是指用于连接一个读进程和一个写进程,以实现它们之间通信的一个共享文件(pipe文件),由于发送进程和接收进程是利用管道进行通信,又称为管道通信
            * 向管道(共享文件)提供输入的发送进程(写进程),以字符流形式将大量的数据送入管道
            * 而接收管道输出的接收进程(读进程),则从管道中读数据
            * 管道机制必须提供能力
                * 互斥
                    * 每次只能有一个进程对管道进行读写
                * 同步
                    * 写完睡眠等待,管道为空时读也睡眠等待
                * 确定对方是否存在
                    * 只有对方存在,才能进行通信

* 信号通信机制
    * 信号基本概念
        * 每个信号都对应一个正整数常量,定义在头文件`<signal.h>`.
        * 每个进程运行时,都要通过信号机制来检查是否有信号到达,若有,便中断正在执行的程序,转向与该信号相对应的处理程序,以完成对该事件的处理,处理结束后再返回到原来的断点继续执行
    * 信号和中断的相似点
        * 采用的异步通信方式是相同的
        * 当有中断请求或检测出有信号时,都暂停正在执行的程序而转去执行相应的处理程序
        * 都在处理完毕后返回到原来的断点
        * 对信号或中断都可以进行屏蔽
    * 信号和中断的区别
        * 中断有优先级,信号没有
        * 信号的处理程序是在用户态下运行的,而中断处理程序是在核心态下运行的
        * 中断响应是即时的,而信号响应通常都有较大的延迟
    * 信号处理方式
        * 第一种是类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。
        * 第二种方法是，忽略某个信号，对该信号不做任何处理，就象未发生过一样。
        * 第三种方法是，对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。进程通过系统调用signal来指定进程对某个信号的处理行为。
    * 信号机制功能
        * 发送信号,使用kill()实现
            * int kill(pid,sig)
                * pid > 0; 核心将信号发送给进程pid
                * pid = 0; 核心将信号发送给与发送进程同组的进程
                * pid = -1 ; 核心将信号发送给所有用户标识符真正等于发送进程的有效用户标识号的进程
            * 信号的发送是指由发送进程把信号发送到指定进程的信号域上的某一位
            * 如果目标进程正在一个可被中断的优先级上睡眠,核心会将它唤醒,发送进程就此结束
            * 一个进程可以同时接收多个信号
        * 预置对信号的处理方式,使用signal()实现
            * signal(sig,function)
                * function 处理函数的地址
                    * function=1,对信号忽略
                    * function=0,默认值，收到信号后终止自己
                    * 其他值，信号处理函数的地址
        * 收受信号的进程按事先的规定完成对相应事件的处理

|名称|信号值| 默认处理动作| 发出信号的原因|
|---|---|---|---|
|SIGHUP| 1 |A |终端挂起或者控制进程终止
|SIGINT| 2 |A |键盘中断（如break键被按下）
|SIGQUIT |3 |C |键盘的退出键被按下
|SIGILL |4 |C |非法指令
|SIGABRT |6 |C |由abort(3)发出的退出指令
|SIGFPE |8 |C |浮点异常
|SIGKILL |9 |AEF |Kill信号
|SIGSEGV |11 |C |无效的内存引用
|SIGPIPE |13 |A |管道破裂: 写一个没有读端口的管道
|SIGALRM |14 |A |由alarm(2)发出的信号
|SIGTERM |15 |A |终止信号
|SIGUSR1 |30,10,16 |A |用户自定义信号1
|SIGUSR2 |31,12,17 |A |用户自定义信号2
|SIGCHLD |20,17,18 |B |子进程结束信号
|SIGCONT |19,18,25 ||进程继续（曾被停止的进程）
|SIGSTOP |17,19,23 |DEF |终止进程
|SIGTSTP |18,20,24 |D |控制终端（tty）上按下停止键
|SIGTTIN |21,21,26 |D |后台进程企图从控制终端读
|SIGTTOU |22,22,27 |D |后台进程企图从控制终端写

处理动作一项中的字母含义如下
* A 缺省的动作是终止进程
* B 缺省的动作是忽略此信号，将该信号丢弃，不做处理
* C 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。
* D 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）
* E 信号不能被捕获
* F 信号不能被忽略

#### 1.3.4.1. 管道

管道是所有Unix提供的进程间通信机制．管道是一个进程之间的单向数据流．一个进程写入管道的所有数据都由内核定向到另一个进程．另一个进程就可以从管道中读取数据．

在Ｕnix的命令中，可以使用"|"操作来创建管道．
```bash
#第一个进程(ls程序)的标准输出被重定向到管道中．第二个进程(more程序)从这个管道中读取输入．
ls | more
#同上
ls ＞ more
#强制more从temp文件中读取数据
more ＜ temp.text
```

管道可以看作是打开的文件．可以使用pipe()系统调用来创建一个管道，这个系统调用返回一对文件描述符，然后进程通过fork()把这两个文件描述符传递给它的子进程．由此与子进程共享管道．进程可以在read()系统调用中使用第一个文件描述符从管道中读取数据．同样也可以在write()系统调用中使用第二个文件描述符向管道中写入数据．




### 1.3.5. 线程
<a href="#menu" >目录</a>

#### 1.3.5.1. 线程的基本概念

引入线程主要是为了提高系统的执行效率，减少处理机的空转时间和在进行调度切换时因保护现场信息所用的时间，便于系统管理．

线程是进程中执行运算的最小单位，即执行处理机调度的基本单位．在引入线程的操作系统中，可以在一个进程内部进行线程器切换，现场保护工作量小．一方面通过共享进程的基本资源而减轻系统的开销．另一方面提高了现场切换的效率．一个进程内的基本调度单位称为线程，这个调度单位可以由操作系统内核控制，也可以由用户程序控制．

**线程和进程的比较:**
* 进程是操作系统资源分配的基本单位，，同一进程的所有线程共享该进程的所有资源
* 线程是分配处理机的基本��位，它与资源分配无关，即真正处理机上运行的是线程
* 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程
* 线程在执行过程中需要协作同步．不同的进程的线程间要利用消息通信的方法实现同步

**引入线程的好处**
* 易于调度,由于线程只能作为独立调度的基本单位，同一进程的多个线程共享进程的资源，所以线程易于切换
* 提高了系统的效率，通过线程可以方便有效地实现并发性，进程可以创建多个线程来执行同一程序的不同部分
* 创建一个线程比创建一个进程所花的时间开销少，创建速度快
* 有利于发挥多处理器的功能，提高进程的并发性


**线程的状态与转换操作**

线程有三种状态：执行，阻塞，就绪
* 派生
    * 线程在进程中派生出来，也可在线程中派生出来
    * unix可使用clonc()和create_thread()来派生不同执行模式下的线程
    * 一个新派生出来的线程具有相应的数据结构指针和变量，这些指针变量作为寄存器上下文放在本线程的寄存器和堆栈中．新派生出来的线程被放入就绪队列中
* 调度
    * 选择一个线程使之进入执行状态
* 阻塞
    * 等待某个事发生则被阻塞．
* 激活
    * 如果阻塞的线程所等待的事件发生，则线程进入就绪状态
* 结束
    * 如果一个线程执行结束，它的寄存器上下文以及堆栈内容等将被释放

#### 1.3.5.2. 多线程的实现

线程有两个基本类型：用户级线程和系统级线程．

* 用户级线程
    * 由用户应用程序建立，并由用户程序负责进行调度和管理，操作系统内核并不知道这些线程的存在，只对进程进行管理．
    * 优点
        * 线程开关的时间消耗小
        * 线程调度算法和操作系统的调度算法无关
        * 用户级线程方法适用于任何操作系统，因为与内核无关
    * 缺点
        * 在一个典型的操作系统中，有许多系统请求正被阻塞，当进程被阻塞时，进程内的所有线程也将被阻塞
        * 一个进程只能由一个线程在ＣＰＵ上运行，不能利用多核ＣＰＵ的优点

* 内核级线程
    * 所有线程的创建，调度和管理全部由操作系统的内核负责完成
    * 优点
        * 内核可以调度一个进程中的多个线程，使其在多个处理机上并行运行，从而提高系统的效率
        * 当进程中的一个线程被阻塞时，进程中的其他线程仍然获得运行的机会
        * 内核本身可以以线程的方式实现
    * 缺点
        *  由于线程调度程序运行在内核态，而应用程序运行在用户态．因此同一进程的线程切换需要经过用户态到核心态，再从核心态到用户态的两次模式转换

#### 1.3.5.3. 线程上下文

操作系统管理很多进程的执行。有些进程是来自各种程序、系统和应用程序的单独进程，而某些进程来自被分解为很多进程的应用或程序。当一个进程从内核 中移出，另一个进程成为活动的，这些��程之间便发生了上下文切换。操作系统必须记录重启进程和启动新进程使之活动所需要的所有信息。这些信息被称作上下 文，它描述了进程的现有状态。当进程成为活动的，它可以继续从被抢占的位置开始执行。进程的上下文信息包括：
* 进程id
* 指向可执行文件的指针
* 栈
* 静态和动态分配的变量的内存
* 处理器寄存器

进程上下文的多数信息都与地址空间的描述有关。进程的上下文使用很多系统资源，而且会花费一些时间来从一个进程的上下文切换到另一个进程的上下文。 线程也有上下文。当线程被抢占时，就会发生线程之间的上下文切换。如果线程属于相同的进程，它 们共享相同的地址空间，因为线程包含在它们所属于的进程的地址空间内。这样，进程需要恢复的多数信息对于线程而言是不需要的。尽管进程和它的线程共享了很 多内容，但最为重要的是其地址空间和资源，有些信息对于线程而言是本地且唯一的，而线程的其他方面包含在进程的各个段的内部。


线程本地（且唯一）的信息包括线程id、处理器寄存器(当线程执行时寄存器的状态，包括程序计数器和栈指针)、线程状态及优先级、线程特定数 据(thread-specific data，TSD)。

线程id是在创建线程时指定的。线程能够访问它所属进程的数据段，因此线程可以读写它所属进程的全局声明数据。进程中一个线程做出的 任何改动都可以被进程中的所有线程以及主线程获得。在多数情况下，这要求某种类型的同步以防止无意的更新。线程的局部声明变量不应当被任何对等线程访问。 它们被放置到线程栈中，而且当线程完成时，它们便会被移走。

#### 1.3.5.4. Linux进程和线程的区别

进程与线程的区别，早已经成为了经典问题。自线程概念诞生起，关于这个问题的讨论就没有停止过。无论是初级程序员，还是资深专家，都应该考虑过这个问题，只是层次角度不同罢了。一般程序员而言，搞清楚二者的概念，在工作实际中去运用成为了焦点。而资深工程师则在考虑系统层面如何实现两种技术及其各自的性能和实现代价。以至于到今天，Linux内核还在持续更新完善(关于进程和线程的实现模块也是内核完善的任务之一)。


首先，简要了解一下进程和线程。对于操作系统而言，进程是核心之核心，整个现代操作系统的根本，就是以进程为单位在执行任务。系统的管理架构也是基于进程层面的。在按下电源键之后，计算机就开始了复杂的启动过程，此处有一个经典问题：当按下电源键之后，计算机如何把自己由静止启动起来的？本文不讨论系统启动过程，请读者自行科普。操作系统启动的过程简直可以描述为上帝创造万物的过程，期初没有世界，但是有上帝，是上帝创造了世界，之后创造了万物，然后再创造了人，然后塑造了人的七情六欲，再然后人类社会开始遵循自然规律繁衍生息。。。操作系统启动进程的阶段就相当于上帝造人的阶段。本文讨论的全部内容都是“上帝造人”之后的事情。第一个被创造出来的进程是0号进程，这个进程在操作系统层面是不可见的，但它存在着。0号进程完成了操作系统的功能加载与初期设定，然后它创造了1号进程(init)，这个1号进程就是操作系统的“耶稣”。1号进程是上帝派来管理整个操作系统的，所以在用pstree查看进程树可知，1号进程位于树根。再之后，系统的很多管理程序都以进程身份被1号进程创造出来，还创造了与人类沟通的桥梁——shell。从那之后，人类可以跟操作系统进行交流，可以编写程序，可以执行任务。

而这一切，都是基于进程的。每一个任务(进程)被创建时，系统会为他分配存储空间等必要资源，然后在内核管理区为该进程创建管理节点，以便后来控制和调度该任务的执行。

进程真正进入执行阶段，还需要获得CPU的使用权，这一切都是操作系统掌管着，也就是所谓的调度，在各种条件满足(资源与CPU使用权均获得)的情况下，启动进程的执行过程。

除CPU而外，一个很重要的资源就是存储器了，系统会为每个进程分配独有的存储空间，当然包括它特别需要的别的资源，比如写入时外部设备是可使用状态等等。有了上面的引入，我们可以对进程做一个简要的总结：

进程，是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。它的执行需要系统分配资源创建实体之后，才能进行。

随着技术发展，在执行一些细小任务时，本身无需分配单独资源时(多个任务共享同一组资源即可，比如所有子进程共享父进程的资源)，进程的实现机制依然会繁琐的将资源分割，这样造成浪费，而且还消耗时间。后来就有了专门的多任务技术被创造出来——线程。

线程的特点就是在不需要独立资源的情况下就可以运行。如此一来会极大节省资源开销，以及处理时间。

从下面几个方面阐述进程和线程的区别。
* 二者的相同点
* 实现方式的差异
* 多任务程序设计模式的区别
* 实体间(进程间，线程间，进线程间)通信方式的不同
* 控制方式的异同
* 资源管理方式的异同
* 个体间辈分关系的迥异
* 进程池与线程池的技术实现差别

|对比维度|多进程|多线程|总结|
|---|---|---|---|
|数据共享，同步|数据共享复杂，需要用到ＩＰＣ，数据共享复杂．数据是分开的，同步简单|共享进程数据，数据共享简单，导致同步复杂|各有优势|
|内存，ＣＰＵ|占用内存多，切换复杂，CPU利用率低|占用内存少，切换简单，CPU利用率高|线程占优|
|创建和销毁|复杂，速度慢|简单，速度快|线程占优|
|编程，调试|简单|复杂|进程占优|
|可靠性|进程间不会互相影响|一个线程挂掉将导致整个进程挂掉|进程占优|
|分布式|适用于多核，多机分布式|适用于多核分布式|进程占优|
 

**二者的相同点**

无论是进程还是线程，对于程序员而言，都是用来实现多任务并发的技术手段。二者都可以独立调度，因此在多任务环境下，功能上并无差异。并且二者都具有各自的实体，是系统独立管理的对象个体。所以在系统层面，都可以通过技术手段实现二者的控制。而且二者所具有的状态都非常相似。而且，在多任务程序中，子进程(子线程)的调度一般与父进程(父线程)平等竞争。

其实在Linux内核2.4版以前，线程的实现和管理方式就是完全按照进程方式实现的。在2.6版内核以后才有了单独的线程实现。 

**实现方式的差异**

进程是资源分配的基本单位，线程是调度的基本单位。

这句经典名言已流传数十年，各种操作系统教材都可见此描述。确实如此，这就是二者的显著区别。读者请注意“基本”二字。相信有读者看到前半句的时候就在心里思考，“进程岂不是不能调度？”，非也！进程和线程都可以被调度，否则多进程程序该如何运行呢！

只是，线程是更小的可以调度的单位，也就是说，只要达到线程的水平就可以被调度了，进程自然可以被调度。它强调的是分配资源时的对象必须是进程，不会给一个线程单独分配系统管理的资源。若要运行一个任务，想要获得资源，最起码得有进程，其他子任务可以以线程身份运行，资源共享就行了。

简而言之，进程的个体间是完全独立的，而线程间是彼此依存的。多进程环境中，任何一个进程的终止，不会影响到其他进程。而多线程环境中，父线程终止，全部子线程被迫终止(没有了资源)。而任何一个子线程终止一般不会影响其他线程，除非子线程执行了exit()系统调用。任何一个子线程执行exit()，全部线程同时灭亡。

其实，也没有人写出只有线程而没有进程的程序。多线程程序中至少有一个主线程，而这个主线程其实就是有main函数的进程。它是整个程序的进程，所有线程都是它的子线程。我们通常把具有多线程的主进程称之为主线程。

从系统实现角度讲，进程的实现是调用fork系统调用：
```c
pid_t fork(void);
```
线程的实现是调用clone系统调用：
```c
int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ...
/* pid_t *ptid, struct user_desc *tls, pid_t *ctid */
);
```

其中，fork()是将父进程的全部资源复制给了子进程。而线程的clone只是复制了一小部分必要的资源。在调用clone时可以通过参数控制要复制的对象。可以说，fork实现的是clone的加强完整版。当然，后来操作系统还进一步优化fork实现——写时复制技术。在子进程需要复制资源(比如子进程执行写入动作更改父进程内存空间)时才复制，否则创建子进程时先不复制。

实际中，编写多进程程序时采用fork创建子进程实体。而创建线程时并不采用clone系统调用，而是采用线程库函数。常用线程库有Linux-Native线程库和POSIX线程库。其中应用最为广泛的是POSIX线程库。因此读者在多线程程序中看到的是pthread_create而非clone。

我们知道，库是建立在操作系统层面上的功能集合，因而它的功能都是操作系统提供的。由此可知，线程库的内部很可能实现了clone的调用。不管是进程还是线程的实体，都是操作系统上运行的实体。

最后，我们说一下vfork() 。这也是一个系统调用，用来创建一个新的进程。它创建的进程并不复制父进程的资源空间，而是共享，也就说实际上vfork实现的是一个接近线程的实体，只是以进程方式来管理它。并且，vfork()的子进程与父进程的运行时间是确定的：子进程“结束”后父进程才运行。请读者注意“结束”二字。并非子进程完成退出之意，而是子进程返回时。一般采用vfork()的子进程，都会紧接着执行execv启动一个全新的进程，该进程的进程空间与父进程完全独立不相干，所以不需要复制父进程资源空间。此时，execv返回时父进程就认为子进程“结束”了，自己开始运行。实际上子进程继续在一个完全独立的空间运行着。举个例子，比如在一个聊天程序中，弹出了一个视频播放器。你说视频播放器要继承你的聊天程序的进程空间的资源干嘛？莫非视频播放器想要窥探你的聊天隐私不成？懂了吧！

**多任务程序设计模式的区别**

由于进程间是独立的，所以在设计多进程程序时，需要做到资源独立管理时就有了天然优势，而线程就显得麻烦多了。比如多任务的TCP程序的服务端，父进程执行accept()一个客户端连接请求之后会返回一个新建立的连接的描述符DES，此时如果fork()一个子进程，将DES带入到子进程空间去处理该连接的请求，父进程继续accept等待别的客户端连接请求，这样设计非常简练，而且父进程可以用同一变量(val)保存accept()的返回值，因为子进程会复制val到自己空间，父进程再覆盖此前的值不影响子进程工作。但是如果换成多线程，父线程就不能复用一个变量val多次执行accept()了。因为子线程没有复制val的存储空间，而是使用父线程的，如果子线程在读取val时父线程接受了另一个客户端请求覆盖了该值，则子线程无法继续处理上一次的连接任务了。改进的办法是子线程立马复制val的值在自己的栈区，但父线程必须保证子线程复制动作完成之后再执行新的accept()。但这执行起来并不简单，因为子线程与父线程的调度是独立的，父线程无法知道子线程何时复制完毕。这又得发生线程间通信，子线程复制完成后主动通知父线程。这样一来父线程的处理动作必然不能连贯，比起多进程环境，父线程显得效率有所下降。

PS：这里引述一个知名的面试问题：多进程的TCP服务端，能否互换fork()与accept()的位置？请读者自行思考。

关于资源不独立，看似是个缺点，但在有的情况下就成了优点。多进程环境间完全独立，要实现通信的话就得采用进程间的通信方式，它们通常都是耗时间的。而线程则不用任何手段数据就是共享的。当然多个子线程在同时执行写入操作时需要实现互斥，否则数据就写“脏”了。

 

**实体间(进程间，线程间，进线程间)通信方式的不同**

* 进程间的通信方式有这样几种：
    * 共享内存
    * 消息队列
    * 信号量
    * 有名管道
    * 无名管道
    * 信号
    * 文件
    * socket

* 线程间的通信方式上述进程间的方式都可沿用，且还有自己独特的几种：
    * 互斥量
    * 自旋锁
    * 条件变量
    * 读写锁
    * 线程信号
    * 全局变量

值得注意的是，线程间通信用的信号不能采用进程间的信号，因为信号是基于进程为单位的，而线程是共属于同一进程空间的。故而要采用线程信号。

综上，进程间通信手段有8种。线程间通信手段有13种。

而且，进程间采用的通信方式要么需要切换内核上下文，要么要与外设访问(有名管道，文件)。所以速度会比较慢。而线程采用自己特有的通信方式的话，基本都在自己的进程空间内完成，不存在切换，所以通信速度会较快。也就是说，进程间与线程间分别采用的通信方式，除了种类的区别外，还有速度上的区别。

另外，进程与线程之间穿插通信的方式，除信号以外其他进程间通信方式都可采用.线程有内核态线程与用户级线程。

 

**控制方式的异同**

进程与线程的身份标示ID管理方式不一样，进程的ID为pid_t类型，实际为一个int型的变量(也就是说是有限的)：

```c
/usr/include/unistd.h:260:typedef __pid_t   pid_t;
/usr/include/bits/types.h:126:# define __STD_TYPE    typedef
/usr/include/bits/types.h:142:__STD_TYPE  __PID_T_TYPE   __pid_t;
/usr/include/bits/typesizes.h:53:#define __PID_T_TYPE   __S32_TYPE
/usr/include/bits/types.h:100:#define   __S32_TYPE      int
```
在全系统中，进程ID是唯一标识，对于进程的管理都是通过PID来实现的。每创建一个进程，内核去中就会创建一个结构体来存储该进程的全部信息：

注：下述代码来自 Linux内核3.18.1
```c
include/linux/sched.h:1235:struct task_struct {

        volatile long state;    /* -1 unrunnable, 0 runnable, >0 stopped */

        void *stack;

...

        pid_t pid;

        pid_t tgid;

...

};
```
每一个存储进程信息的节点也都保存着自己的PID。需要管理该进程时就通过这个ID来实现(比如发送信号)。当子进程结束要回收时(子进程调用exit()退出或代码执行完)，需要通过wait()系统调用来进行，未回收的消亡进程会成为僵尸进程，其进程实体已经不复存在，但会虚占PID资源，因此回收是有必要的。

线程的ID是一个long型变量：
```c
/usr/include/bits/pthreadtypes.h:60:typedef unsigned long int pthread_t;
```
它的范围大得多，管理方式也不一样。线程ID一般在本进程空间内作用就可以了，当然系统在管理线程时也需要记录其信息。其方式是，在内核创建一个内核态线程与之对应，也就是说每一个用户创建的线程都有一个内核态线程对应。但这种对应关系不是一对一，而是多对一的关系，也就是一个内核态线程可以对应着多个用户级线程。还是请读者参看《Linux线程的实质》普及相关概念。此处贴出blog地址：

http://my.oschina.net/cnyinlinux/blog/367910

对于线程而言，若要主动终止需要调用pthread_exit() ，主线程需要调用pthread_join()来回收(前提是该线程没有被detached，相关概念请查阅线程的“分离属性”)。像线发送线程信号也是通过线程ID实现的。

 

**资源管理方式的异同**

进程本身是资源分配的基本单位，因而它的资源都是独立的，如果有多进程间的共享资源，就要用到进程间的通信方式了，比如共享内存。共享数据就放在共享内存去，大家都可以访问，为保证数据写入的安全，加上信号量一同使用。一般而言，共享内存都是和信号量一起使用。消息队列则不同，由于消息的收发是原子操作，因而自动实现了互斥，单独使用就是安全的。

线程间要使用共享资源不需要用共享内存，直接使用全局变量即可，或者malloc()动态申请内存。显得方便直接。而且互斥使用的是同一进程空间内的互斥量，所以效率上也有优势。

实际中，为了使程序内资源充分规整，也都采用共享内存来存储核心数据。不管进程还是线程，都采用这种方式。原因之一就是，共享内存是脱离进程的资源，如果进程发生意外终止的话，共享内存可以独立存在不会被回收(是否回收由用户编程实现)。进程的空间在进程崩溃的那一刻也被系统回收了。虽然有coredump机制，但也只能是有限的弥补。共享内存在进程down之后还完整保存，这样可以拿来分析程序的故障原因。同时，运行的宝贵数据没有丢失，程序重启之后还能继续处理之前未完成的任务，这也是采用共享内存的又一大好处。

总结之，进程间的通信方式都是脱离于进程本身存在的，是全系统都可见的。这样一来，进程的单点故障并不会损毁数据，当然这不一定全是优点。比如，进程崩溃前对信号量加锁，崩溃后重启，然后再次进入运行状态，此时直接进行加锁，可能造成死锁，程序再也无法继续运转。再比如，共享内存是全系统可见的，如果你的进程资源被他人误读误写，后果肯定也是你不想要的。所以，各有利弊，关键在于程序设计时如何考量，技术上如何规避。这说起来又是编程技巧和经验的事情了。

 

**个体间辈分关系的迥异**

进程的备份关系森严，在父进程没有结束前，所有的子进程都尊从父子关系，也就是说A创建了B，则A与B是父子关系，B又创建了C，则B与C也是父子关系，A与C构成爷孙关系，也就是说C是A的孙子进程。在系统上使用pstree命令打印进程树，可以清晰看到备份关系。

多线程间的关系没有那么严格，不管是父线程还是子线程创建了新的线程，都是共享父线程的资源，所以，都可以说是父线程的子线程，也就是只存在一个父线程，其余线程都是父线程的子线程。

 

**进程池与线程池的技术实现差别**

我们都知道，进程和线程的创建时需要时间的，并且系统所能承受的进程和线程数也是有上限的，这样一来，如果业务在运行中需要动态创建子进程或线程时，系统无法承受不能立即创建的话，必然影响业务。综上，聪明的程序员发明了一种新方法——池。

在程序启动时，就预先创建一些子进程或线程，这样在需要用时直接使唤。这就是老人口中的“多生孩子多种树”。程序才开始运行，没有那么多的服务请求，必然大量的进程或线程空闲，这时候一般让他们“冬眠”，这样不耗资源，要不然一大堆孩子的口食也是个负担啊。对于进程和线程而言，方式是不一样的。另外，当你有了任务，要分配给那些孩子的时候，手段也不一样。下面就分别来解说。
**进程池**
首先创建了一批进程，就得管理，也就是你得分开保存进程ID，可以用数组，也可用链表。建议用数组，这样可以实现常数内找到某个线程，而且既然做了进程池，就预先估计好了生产多少进程合适，一般也不会再动态延展。就算要动态延展，也能预估范围，提前做一个足够大的数组。不为别的，就是为了快速响应。本来错进程池的目的也是为了效率。

接下来就要让闲置进程冬眠了，可以让他们pause()挂起，也可用信号量挂起，还可以用IPC阻塞，方法很多，分析各自优缺点根据实际情况采用就是了。

然后是分配任务了，当你有任务的时候就要让他干活了。唤醒了进程，让它从哪儿开始干呢？肯定得用到进程间通信了，比如信号唤醒它，然后让它在预先指定的地方去读取任务，可以用函数指针来实现，要让它干什么，就在约定的地方设置代码段指针。这也只是告诉了它怎么干，还没说干什么(数据条件)，再通过共享内存把要处理的数据设置好，这也子进程就知道怎么做了。干完之后再来一次进程间通信然后自己继续冬眠，父进程就知道孩子干完了，收割成果。

最后结束时回收子进程，向各进程发送信号唤醒，改变激活状态让其主动结束，然后逐个wait()就可以了。

**线程池**
线程池的思想与上述类似，只是它更为轻量级，所以调度起来不用等待额外的资源。
要让线程阻塞，用条件变量就是了，需要干活的时候父线程改变条件，子线程就被激活。
线程间通信方式就不用赘述了，不用繁琐的通信就能达成，比起进程间效率要高一些。
线程干完之后自己再改变条件，这样父线程也就知道该收割成果了。
整个程序结束时，逐个改变条件并改变激活状态让子线程结束，最后逐个回收即可。


**分类**

根据进程与线程的设置，操作系统大致分为如下类型：
* 单进程、单线程，MS-DOS大致是这种操作系统；
* 多进程、单线程，多数UNIX(及类UNIX的LINUX)是这种操作系统；
* 多进程、多线程，Win32(Windows NT/2000/XP等)、Solaris 2.x和OS/2都是这种操作系统；
* 单进程、多线程，VxWorks是这种操作系统。

### 1.3.6. 处理机调度和死锁
<a href="#menu" >目录</a>

#### 1.3.6.1. 处理机调度的层次
<a href="#menu" >目录</a>

* 作业
    * 用户向计算机提交任务的实体
    * 一个作业是指一次应用业务处理过程中，从输入开始到输出结束，用户要求计算机所做的有关该次业务处理的全部过程
    * 一个作业总是由一个或者多个的进程组成

* 调度层次
    * 作业调度(高级调度或者长调度)
        * 用于选择把外存上处于后备队列中的那些作业调入内存，并且为它们创建进程，分配必要的资源．然后，再将新创建的进程排在就绪队列上，准备执行
    * 对换(交换调度或者中级调度)
        * 按照给定的原则和策略，将处于外存交换区中的就绪状态或等待状态的进程调入内存，或把内存就绪状态或内存等待状态的进程交换到外存交换区
        * 交换调度主要涉及到内存管理和扩充
    * 进程调度(低级调度或者微观调度)
        * 按照某种策略和算法，将处理机分配给一个处于就绪状态的进程
        * 分类
            * 非抢占式的
                * 不允许进程抢占已经分配出去的处理机，必须等到执行的进程执行完或者等待进程因为某种原因（比如wait操作）不能继续执行
                * 实现简单，系统开销小，但很难满足紧急任务的要求
            * 抢占式的
                * 允许调度程序根据某种原则暂停正在执行的进程，将处理机收回，分配给另一个处于就绪或者等待状态的进程

#### 1.3.6.2. 进程调度

* 进程调度的功能
    * 记录系统中所有进程的执行情况
    * 从就绪状态队列中选择一个进程
    * 进行进程上下文的切换

* 进程调度的时机
    * 完成任务
        * 正在执行的进程运行完成，主动释放对ＣＰＵ的控制
    * 等待资源
        * 由于等待某些资源或者事件发生，放弃ＣＰＵ，进入阻塞状态
    * 运行时间到
        * 在分时系统中，当前进程使用完规定的时间片，时钟中断，使该进程让出CPU
    * 进入睡眠状态
    * 发现标志
    * 优先级变化
        * 就绪队列中的某进程的优先级高于当前执行进程的优先级时，将引起进程调度


* 进程上下文的切换
    * 进程的上下文由正文段，数据断，硬件寄存器的内容以及有关的数据结构组成．硬件寄存器主要包括存放CPU将要执行的下条指令地址的程序计数器，指出机器与进程相关联的硬件状态的处理机状态寄存器PS .存放过程调用时所传递参数的通用寄存器R和堆栈指针寄存器S等．数据结构包括PCB等在内的所有与执行该进程相关的管理和控制用表格，数组，链等．当进程调度发生时，要做进程上下文切换
    * 进程上下文切换时
        * 决定是否要做以及是否允许做上下文切换
        * 保存当前执行的进程的上下文
        * 选择一个处于就绪状态的进程
        * 使被选中的进程执行

#### 1.3.6.3. 调度算法
<a href="#menu" >目录</a>


##### 1.3.6.3.1. 优先级调度算法

系统或者用户会按照某种原则，为作业或者进程设定一个优先级．在进行调度时，调度程序根据优先级进行调度．

* 非抢占式优先级调度算法
    * 系统在就绪队列中寻找优先级最高的进程执行，要么等待执行结束或则进入阻塞状态才进行进程调度
* 抢占式优先级调度算法
    * 系统在就绪队列中寻找优先级最高的进程执行，如果此时就绪队列中出现优先级更高的进程，会切换到该进程执行．
    * 一般用在对实时性要求较高的系统

* 优先级的类型
    * 静态优先级
        * 创建进程时确定的，且在进程执行期间保持不变
    * 动态优先级
        * 随着进程执行而改变，以便获得更好的调度性能

##### 1.3.6.3.2. 轮转调度算法

时间片轮转法主要用于分时系统中的进程调度．轮转调度的实现原理是系统把　所有进入就绪状态的进程按先入先出的原则排成一个队列．新来的进程加到末尾，每当执行进程调度时，位于队首的进程被执行一段时间，当执行完后系统的定时器发出中断，进而选择新的进程继续执行．


#### 1.3.6.4. Linux的进程调度算法

Linux系统的调度程序就是内核中的schedule()函数，它的主要任务是在就绪队列run_queue中选出一个进程并投入运行．
schedule()函数需要确定以下参数:
* 进程调试算法policy
* 进程过程中剩余的时间片counter
* 进程静态优先级(已经取消)
* 实时进程的优先级rt_priority
* 用户可控制的nice因子


#### 1.3.6.5. 产生死锁的原因和必要条件
<a href="#menu" >目录</a>

死锁是指多个进程循环等待其他进程占有的资源，因为额无限期僵持下去的局面，也可以说死锁是进程之间互相等待永不发生的事件，如果没有外界的作用，死锁中的各个进程将永远处于阻塞状态．

* 死锁产生的原因
    * 各进程竞争有限的资源
    * 进程推进顺序不当

* 死锁产生的必要条件
    * 互斥条件
        * 对于一个排他性资源，某一时刻最多只能由一个进程占有，不能同时分配给两个以上的进程．只有占有该资源的进程放弃之后，其他进程才能占用该资源
    * 占有且申请条件
        * 进程至少已经占有一个资源，但又申请新的资源，由于该资源已经被其他进程占有，此时该进程阻塞，但是，它在等待新资源时，仍不释放已占有的资源
    * 不可抢占条件（不剥夺条件）
        * 进程未释放该资源，其他进程不可强行剥夺该进程所占有的资源
    * 环路条件
        * 存在一个进程序列{P1,P2....Pn},P1等待进程P2的资源，P2等待进程P3的资源．．．．．Pn等待进程P1的资源.形成一个循环等待的环路

4个条件中只要有一个不满足，则死锁不会发生．这是预防死锁所需要考虑的问题．

* 解决死锁的基本方法
    * 死锁的预防
        * 采取某种策略，减少并发进程对同一个资源的请求
    * 死锁的避免
        * 给定一个合适的安全的进程推进顺序
    * 死锁的检测
        * 系统能够检测死锁的发生
    * 死锁的解除




### 1.3.7. 存储器管理
<a href="#menu" >目录</a>

#### 1.3.7.1. 存储器的层次结构
<a href="#menu" >目录</a>

#### 1.3.7.2. 程序的装入和链接
<a href="#menu" >目录</a>

#### 1.3.7.3. 连续分配方式

<a href="#menu" >目录</a>

#### 1.3.7.4. 基本分段存储管理方式
<a href="#menu" >目录</a>

#### 1.3.7.5. 虚拟存储器的基本概念
<a href="#menu" >目录</a>

#### 1.3.7.6. 请求分页存储管理方式
<a href="#menu" >目录</a>

#### 1.3.7.7. 页面置换算法
<a href="#menu" >目录</a>

#### 1.3.7.8. 请求分段管理方式
<a href="#menu" >目录</a>

### 1.3.8. 设备管理
<a href="#menu" >目录</a>

#### 1.3.8.1. I/O系统
<a href="#menu" >目录</a>

#### 1.3.8.2. I/O控制方式
<a href="#menu" >目录</a>

#### 1.3.8.3. 缓冲管理
<a href="#menu" >目录</a>

#### 1.3.8.4. I/O软件
<a href="#menu" >目录</a>

#### 1.3.8.5. 设备分配
<a href="#menu" >目录</a>

#### 1.3.8.6. 磁盘存储器的管理
<a href="#menu" >目录</a>



### 1.3.9. 文件管理
<a href="#menu" >目录</a>

#### 1.3.9.1. 文件和文件系统
<a href="#menu" >目录</a>

* 文件类型
    * 按文件的数据形式分类
        * 源文件
            * 由源程序和数据构成的文件
        * 目标文件
            * 由相应的编译程序编译而成的文件
        * 可执行文件
            * 由目标文件连接而成的文件
    * 按用途分类
        * 系统文件
        * 库文件
        * 用户文件
    * 按存取权限分类
        * 只读文件
        * 读写文件
        * 可执行文件
    * 按保存时间分类
        * 临时文件
        * 档案文件
        * 永久文件


#### 1.3.9.2. 文件的结构
<a href="#menu" >目录</a>

* 文件结构：文件的组织形式
    * 文件的逻辑结构
        * 从用户观察和使用文件的角度出发所定义的文件组织形式
    * 文件的物理结构(存储形式)
        * 从系统的角度考察文件在实际存储设备上的存放形式

##### 1.3.9.2.1. 文件的逻辑结构

从用户对文件元素的操作出发，建立文件的逻辑结构．文件的逻辑结构决定对文件构成元素的操作方法

* 有结构的文件
    * 在逻辑上可被砍成是一组连续顺序的记录的集合，比如多个键值对
* 无结构的文件
    * 字符流文件，字符序列组成的文件

* 文件存储方式
    * 顺序存储方式
        * 按照文件的逻辑地址依次存取，也就是说每条记录都有自己的位移，通过位移可以读取到记录
    * 随机存取方式
        * 基于磁盘的文件模式，又称为直接存取方式，允许用户随意存取文件中的任何一个物理位置，而不管上次存取了哪一个记录．

##### 1.3.9.2.2. 文件的物理结构

文件的物理结构是指文件在外部存储器上的存取方式，以及它与文件逻辑结构之间的对应关系，即文件的存储结构

* 连续文件
    * 一个文件顺序存放在外存的若干个连续物理块中
* 串联结构文件
* 索引文件结构
    * 系统为每个文件建立了一张索引表，索引表是文件逻辑快号和物理块号的对照表


#### 1.3.9.3. 外存的分配方式
<a href="#menu" >目录</a>

#### 1.3.9.4. 目录管理
<a href="#menu" >目录</a>

文件目录是查看，读取外存中所存放文件的数据结构，用于文件描述和文件控制，实现按名存取和文件共享和保护，随文件的建立而创建，随文件的删除而消亡

#### 1.3.9.5. 文件存储空间的管理
<a href="#menu" >目录</a>

#### 1.3.9.6. 文件共享与文件保护
<a href="#menu" >目录</a>

#### 1.3.9.7. 数据一致性控制
<a href="#menu" >目录</a>


### 1.3.10. Ｌinux网络基础
<a href="#menu" >目录</a>

#### 1.3.10.1. 网络配置文件

**/etc/hostname**
系统的主机名称和完全域名
```
$ cat /etc/hostname
lgj-Lenovo-G470

```

**/etc/host.conf**
指定如何解析主机名，Linux通过解析器库获得主机名对应的ＩＰ地址
```
$ cat /etc/host.conf
# The "order" line is only used by old versions of the C library.
# 指定主机名查询顺序，这里规定先查询／etc/hosts文件，再使用ＤＮＳ解析域名
order hosts,bind
# 表示/etc／host文件中指定的主机可以有多个地址，拥有多个ＩＰ地址的主机一般称为具有多个网络接口
multi on

```

**/etc/service**
服务名和端口号之间的映射.格式：服务名　端口号／端口类型
```
tcpmux		1/tcp				# TCP port service multiplexer
echo		7/tcp
echo		7/udp
discard		9/tcp		sink null
discard		9/udp		sink null
systat		11/tcp		users
daytime		13/tcp
daytime		13/udp
netstat		15/tcp

```

### 1.3.11. 系统安全性
<a href="#menu" >目录</a>


### 1.3.12. Unix系统内核结构
<a href="#menu" >目录</a>


## 1.4. Linux系统编程
<a href="#menu" >目录</a>

### 1.4.1. 标准
<a href="#menu" >目录</a>

#### 1.4.1.1. POSIX 

POSIX(Portable Operating System Interface for Computing Systems)是由IEEE 和ISO/IEC 开发的一簇标准。该标准是基于现有的UNIX 实践和经验，描述了操作系统的调用服务接口，用于保证编制的应用程序可以在源代码一级上在多种操作系统上移植运行。它是在1980 年早期一个UNIX 用户组(usr/group)的早期工作的基础上取得的。该UNIX 用户组原来试图将AT&T 的系统V 和Berkeley CSRG的BSD 系统的调用接口之间的区别重新调和集成，从而于1984 年产生了/usr/group 标准。1985 年，IEEE操作系统技术委员会标准小组委员会(TCOS-SS)开始在ANSI 的支持下责成IEEE 标准委员会制定有关程序源代码可移植性操作系统服务接口正式标准。到了1986 年4 月，IEEE 就制定出了试用标准。第一个正式标准是在1988 年9 月份批准的(IEEE 1003.1-1988)，也既以后经常提到的POSIX.1 标准。

POSIX(Portable Operating System Interface)可移植操作系统接口，这样的简写完全是为了和UNIX读起来更像而已。它是由IEEE(电子和电气工程师协会)开发，由ANSI(美国国家标准化学会)和OSI(国际标准化组织)两个机构标准化。由于早起各厂家对UNIX的开发各自为政，互相竞争，造成UNIX版本混乱，给软件移植造成困难，不利于UNIX长期发展，基于此，IEEE开发了POSIX，在源码级别定义了一组UNIX操作系统接口。

  目前POSIX已经成为类UNIX（Unix-like）操作系统编程的通用接口，极大方便了类UNIX环境下应用程序源码级的可移植性。Glibc(GNU C Library),即Ｃ运行库，是Linux系统中最底层的API，它就是完全按照POSIX标准编写的。

#### 1.4.1.2. Sytem V
 
System V， 曾经也被称为 AT&T System V，是Unix操作系统众多版本中的一支。它最初由 AT&T 开发，在1983年第一次发布。一共发行了4个 System V 的主要版本：版本1、2、3 和 4。System V Release 4，或者称为SVR4，是最成功的版本，成为一些UNIX共同特性的源头，例如 ”SysV 初始化脚本“ (/etc/init.d)，用来控制系统启动和关闭，System V Interface Definition (SVID) 是一个System V 如何工作的标准定义。

AT&T 出售运行System V的专有硬件，但许多(或许是大多数)客户在其上运行一个转售的版本，这个版本基于 AT&T 的实现说明。流行的SysV 衍生版本包括 Dell SVR4 和 Bull SVR4。当今广泛使用的 System V 版本是 SCO OpenServer，基于 System V Release 3，以及SUN Solaris 和 SCO UnixWare，都基于 System V Release 4。

System V 是 AT&T 的第一个商业UNIX版本(UNIX System III)的加强。传统上，System V 被看作是两种UNIX”风味”之一(另一个是 BSD)。然而，随着一些并不基于这两者代码的UNIX实现的出现，例如 Linux 和 QNX， 这一归纳不再准确，但不论如何，像POSIX这样的标准化努力一直在试图减少各种实现之间的不同。

System V(System Five),是Unix操作系统众多版本中的一支，就是当年UNIX厂家混战中，比较强大的一个诸侯王，最初由 AT&T 开发，在1983年第一次发布。一共发行了4个 System V 的主要版本：1、2、3 和 4，比如：System V Release 4，或者称为SVR4，是最成功的版本，比如现今依然使用的操作系统ＳUN Solaris 和 SCO UnixWare，都基于 System V Release 4的，SUN公司我想大家都知道吧，依然是现在商用服务器操作系统重要提供商，但是我们常用的Linux操作系统并不是基于此的，但是这里要感谢POSIX这样标准化的努力，是它兼容了绝大部分System V的规格，减少了各类操作系统之间移植的麻烦。

#### 1.4.1.3. 使用 

照上面所说的System V和POXIS是一种应用于系统的接口协议，POXIS相对于System V可以说是比较新的标准，语法相对简单。

在linux/unix系统编程中支持System V和POXIS。我们常见的一个名词就是POSIX IPC和System V IPC。IPC的全称是Inter-process Comminication，就是进程间通信。

在POSIX IPC中，在POSIX IPC中，每个IPC对象是有名称的，而且名称是一个很重要的概念，posix ipc使用ipc的名称作为ipc的标识。mq_open sem_open shm_open三个函数的第一个参数就是这个名称，这个名称不一定是在文件系统中存在的名称。 要使用IPC对象，需要创建或者打开，这与文件操作类似，主要是使用mq_open、sem_open、shm_open 函数操作。在创建或者打开ipc对象时需要指定操作的mode，例如O_RONLY、O_WRONLY、O_RDWR、O_CREAT、O_EXCL 等，IPC对象是有一定权限的，与文件的权限类似。

在System V IPC中，System v ipc中有一个重要的类型是key_t，在msget、semget、shmget函数操作中都需要利用这个类型是参数。 


### 1.4.2. 基本概念
<a href="#menu" >目录</a>

#### 1.4.2.1. 操作系统的核心
<a href="#menu" >目录</a>

* 操作系统
    * 完整的软件包，包括用来管理计算机资源的核心层软件，以及附带的所有标准软件工具
    * 更狭义的范围内，是指管理和分配计算机资源的核心层软件(内核)

虽然在没有内核的情况下，计算机也能运行程序，但是有了内核会简化程序的编写，比如用户程序不用直接去访问计算机硬件．

* 内核职责
    * 进程调度
        * Linux属于抢占式多任务操作系统
    * 内存管理
        * Linux采用虚拟内存管理机制
            * 优势
                * 进程和进程之间，进程和内核之间彼此隔离，因此一个进程无法读取或者修改内核或者其他进程的内存内容
                * 只需将进程的一部分保持在内存中，这不但降低了每个进程对内存的需求量，而且还能在RAM中加载更多的进程．
    * 提供文件系统
        * 内核在磁盘之上提供了文件系统，允许对文件进行创建等操作
    * 创建和终止进程
        * 内核可以将新程序载入内存，为其提供运行所需的资源．一旦进程执行结束，内核还要保证其所持有的资源　，以供后续程序使用
    * 对设备的访问
        * 内核为程序访问设备(鼠标，键盘，磁盘等)提供了简化版的标准接口，同时还要仲裁多个进程对每一个设备的访问
    * 联网
    * 提供系统调用应用编程接口(API)
        * 进程可以使用这些接口请求内核去执行相关的任务

* 内核态和用户态
    * 现代处理器架构一般允许CPU至少在两种不同状态下运行，(用户态和内核态)．执行硬件指令可以在两种状态之间来回切换
    * 与之对应，可以将虚拟内存划分为用户空间部分和内核空间部分．
    * 在用户态下，cpu只能访问被标记为用户空间的内存．试图访问属于内核空间的内存会引发硬件异常．当运行于核心态时，两个内存空间都可以访问．
    * 但是有些操作只能在内核空间下执行，比如访问内存管理硬件等．这种机制保证了用户态下不会执行非法操作导致系统出现异常

#### 1.4.2.2. shell
<a href="#menu" >目录</a>

shel是一种具有特殊用途的程序，主要啊用于读取用户输入的命令，并执行相应的程序以响应命令．也称为命令解释器．

* 几种常见的shell
    * Bourne（sh）
    * C shell (csh)
    * Korn shell （ksh）
    * Bourne again shell(bash)



#### 1.4.2.3. 用户和组
<a href="#menu" >目录</a>

系统会为每个用户的身份做唯一标识，用户可隶属于多个组．

* 超级用户
    * 超级用户在系统中享有特权，用户ID为，通常登录名是root.超级用户可以访问系统中的任何文件．也能发送信号干预系统运行的所有用户进程．系统管理员可以使用草机用户帐号来进行各种系统管理用户．


#### 1.4.2.4. 单根目录层级，目录，链接以及文件
<a href="#menu" >目录</a>

unix的根目录是"／"，所有的文件和目录都是根目录的子孙．

文件不仅仅指文本文件，还包括设备，管道，套接字以及符号链接．

* 一切皆文件
    * 首先通常在windows中是文件的东西,它们在linux中也是文件
    * 一些在windows中不是文件的东西, 比如进程, 磁盘, 也被抽象成了文件. 你可以使用访问文件的方法访问它们获得信息.
    * 一些很离谱的东西, 比如管道, 比如/dev/zero(一个可以读出无限个0的文件) /dev/null(一个重定向进去之后就消失了的文件). 它们也是文件
    * 类似于socket这样的东西, 使用的接口跟文件接口也是一致的.
带来的好处就是, 你可以使用同一套api(read, write)和工具(cat , 重定向, 管道)来处理unix中大多数的资源.这就使得组合了简单的命令和字符处理工具(awk, sed)之后, shell脚本就能发挥出强大的功能.

Linux下文件一般有如下几种类型
* 普通文件          # xxx.log
* 目录              # /usr/ /home/
* 字符设备文件      # /dev/tty的属性是 crw-rw-rw- ，注意前面第一个字符是 c ，这表示字符设备文件,比如猫等串口设备
* 块设备文件        # /dev/hda1 的属性是 brw-r----- ，注意前面的第一个字符是b，这表示块设备，比如硬盘，光驱等设备
* 套接字文件        # /var/lib/mysql/mysql.sock srwxrwxrwx
* 管道              # pipe
* 符号链接文件      # softlink...


每个目录至少包含两条记录，＂．＂和＂．．＂，前者指向自身目录，后者指向上级目录．根目录的".."是其自身．

绝对路径名以"/"开始，相对路径基于当前的目录，缺少起始的"/".


#### 1.4.2.5. 文件IO模型 
<a href="#menu" >目录</a>

unix系统IO模型的特点是I/O通用性，同一套系统调用(open(),read(),write(),close()等)所执行的操作，可适用于所有文件．应用程序发起IO请求，内核会将其转化为相应的文件系统操作．或者设备驱动程序操作．也就是说内核提供了上面的通用接口．但是内核层面会根据访问文件的差异实现不同的代码．

就本质而言，内核只提供一种文件类型:字节流序列．在处理磁盘文件，磁盘或者磁盘驱动器时，可以通过lseek来实现随机访问．

* 文件描述符
    * 文件描述符 是 用来访问资源(文件，输入输出设备等)的一种抽象指示符。
    * 文件描述符 是POSIX(Portable Operating System Interface)规范的组成部分
    * 文件描述符 通常是非负整数，C 语言中使用int类型

* 系统默认的FDs
    * 每一个 Unix 进程中，通常会有三个预制的 FD。它们分别是
        * 标准输入 Standard input
        * 标准输出 Standard output
        * 标准错误(输出) Standard error
    * 其对应的行为是
        * 标准输入 用于程序接受数据
        * 标准输出 用于程序输出数据
        * 标准错误 用于程序输出错误或者诊断信息
* FD 数量限制
    * 出于稳定系统性能和避免因为过多打开文件导致CPU和RAM占用居高的考虑，系统都会设置了一个最大可用的 FD 数量。
    * FD上限值通常不小，一般应用很难达到。
    * 限制类型
        * hard limit 由系统管理权限人员设定，是soft limit 可以设置的上限
        * soft limit 当前用户设置，用来限定进程，通常小于（但不能超过）hard limit值。

```bash
#查看soft limit 设置	
ulimit -nS	
4864	
#查看 hard limit 设置	
ulimit -nH	
unlimited
```
* 进程退出与 FD 关系
    * 因为file descriptor table 存在于 PCB (进程控制块，Process Control Block) 中，进程退出后所有的 FD都需要关闭处理掉。

* 同一路径 与 FD 关系
    * 同一文件，多次打开，FD值不同
    * 同一文件，读写模式不同打开，FD值也不同
* 打开文件过多会怎样
    * open返回值会出现 -1
    * 通常会导致进程无法进行，甚至是崩溃

    
#### 1.4.2.6. 程序
<a href="#menu" >目录</a>

#### 1.4.2.7. 进程
<a href="#menu" >目录</a>

进程是正在执行的程序实例．也是受操作系统资源管理的基本单位．执行程序时，内核会将程序代码载入虚拟内存，为程序变量分配空间，建立内核数据结构．以记录与进程相关的各种信息，比如进程id，用户id等信息．

在内核看来，进程是一个个实体，内核必须在它们之间共享各种计算机资源．对于像内存这样的受限资源来说，内核一开始会为进程分配一定数量的资源，并在进程的生命周期内，统筹该进程和整个系统对资源的需求．对这一分配进行调整．程序终止时，内核会释放所有此类资源，供其他进程使用．

* 进程的内存布局
    * 文本:程序的指令
    * 数据:程序使用的静态变量
    * 堆：程序可从该区域动态分配内存
    * 栈：随函数调用＼返回而增减的一片内存，用于为局部变量和函数调用链接信息分配存储空间


* 创建进程和执行程序
    * 进程可以使用系统调用fork()来创建一个新进程．调用fork()的进程称为父进程．新创建的进程为子进程，内核通过对父进程的复制来创建子进程．子进程从父进程处继承数据段，栈段，以及堆段的副本后，可以修改这些内容，但是不会影响父进程的原版内容．在内存中标记为只读的程序文本则由父子进程共享

每一个进程都有一个唯一的整数型标识符(PID).此外，每一个进程还具有一个父进程标识符(PPID)

* 资源限制
    * 每个进程都会消耗诸如打开文件，内存，以及cpu时间之类的资源．使用系统调用setrlimit()，进程可以为自己消耗的各类资源设定上限．
    * 软限制(soft　limit),限制进程可以消耗的资源总量．硬限制(hard limit),软限制的调整上限．
    * 非特权用户可调整软限制0－相应的硬限制之间的值．但是硬限制只能调低不能调高．
    * 由fork（）创建的新进程，会继承其父进程对资源的限制值

#### 1.4.2.8. 内存映射
<a href="#menu" >目录</a>




#### 1.4.2.9. 静态库和共享库
<a href="#menu" >目录</a>

#### 1.4.2.10. 进程间通信和同步
<a href="#menu" >目录</a>

#### 1.4.2.11. 信号 
<a href="#menu" >目录</a>

#### 1.4.2.12. 线程
<a href="#menu" >目录</a>

#### 1.4.2.13. 进程组和shell任务控制
<a href="#menu" >目录</a>

#### 1.4.2.14. 会话，控制终端和控制进程
<a href="#menu" >目录</a>

#### 1.4.2.15. 伪终端
<a href="#menu" >目录</a>

#### 1.4.2.16. 日期和时间
<a href="#menu" >目录</a>

#### 1.4.2.17. 客户端服务器架构
<a href="#menu" >目录</a>

#### 1.4.2.18. 实时性
<a href="#menu" >目录</a>

#### 1.4.2.19. ／proc文件系统
<a href="#menu" >目录</a>




## 1.5. Unix环境编程
<a href="#menu" >目录</a>

### 1.5.1. 基本概念

<a href="#menu" >目录</a>

* **内核**
管理和分配计算机资源(CPU,内存等)的核心层软件

* **内核任务**
    * 进程调度，Linux是抢占式多任务操作系统，内核需要协调好多个任务的执行。`
    * 内存管理
    * 提供文件系统
    * 创建和终止进程
    * 对设备的访问
    * 联网
    * 提供系统应用调用API接口

* **内核态和用户态**
    * 可将虚拟内存区域划分为用户空间和内核空间两部分
    * 在用户态下只能访问用户空间，试图访问内核空间将会报硬件错误
    * 在内核态下两者都可以访问到

* **文件描述符**
    * Linux下一切皆是文件，每打开一个文件或者Socket,都会获得一个文件描述符(整型)来唯一标识。

* **进程**
    * 进程是正在执行的程序实例，执行程序时，内核会将程序代码载入虚拟内存，为程序变量分配空间，建立内核记账数据结构，以记录与进程有关的各种信息（比如，进程ID，用户ID，组ID以及终止状态）
    * 进程内存布局
        * 文本: 程序的指令
        * 数据: 程序使用的静态变量
        * 堆:程序可从该区域动态分配额外的内存
        * 栈:随函数调用，返回而增减的一片内存，用于为局部变量和函数调用链接信息分配存储空间
    * 创建进程和执行程序
        * fork进行创建
        * 内核通过对父进程的复制来创建子进程
        * 子进程从父进程处继承数据段、栈段、以及堆段的副本，即使修改也不会互相影响，两者之间的内存空间是独立的
    * 进程IP
        * 每一个进程都有一个唯一标识符PID，如果有父进程，还有一个父进程PPID

### 1.5.2. IO模型
<a href="#menu" >目录</a>

**概念理解**
 在进行网络编程时，我们常常见到同步(Sync)/异步(Async)，阻塞(Block)/非阻塞(Unblock)四种调用方式：
 * 同步
    * 所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。
    * 例如普通B/S模式（同步）：提交请求->等待服务器处理->处理完毕返回 这个期间客户端浏览器不能干任何事
* 异步：
    * 异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。
    * 例如 ajax请求（异步）: 请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕
* 阻塞
    * 阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。
    * 有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。 例如，我们在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息。

* 非阻塞
    * 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。

**对象的阻塞模式和阻塞函数调用**
对象是否处于阻塞模式和函数是不是阻塞调用有很强的相关性，但是并不是一一对应的。阻塞对象上可以有非阻塞的调用方式，我们可以通过一定的API去轮询状 态，在适当的时候调用阻塞函数，就可以避免阻塞。而对于非阻塞对象，调用特殊的函数也可以进入阻塞调用。函数select就是这样的一个例子。

* 同步，就是我调用一个功能，该功能没有结束前，我死等结果。
* 异步，就是我调用一个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知）
* 阻塞，就是调用我（函数），我（函数）没有接收完数据或者没有得到结果之前，我不会返回。
* 非阻塞，就是调用我（函数），我（函数）立即返回，通过select通知调用者

 

同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！
阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！


对于举个简单c/s 模式：

 

同步：提交请求->等待服务器处理->处理完毕返回这个期间客户端浏览器不能干任何事
异步：请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕
同步和异步都只针对于本机SOCKET而言的。
同步和异步,阻塞和非阻塞,有些混用,其实它们完全不是一回事,而且它们修饰的对象也不相同。
阻塞和非阻塞是指当进程访问的数据如果尚未就绪,进程是否需要等待,简单说这相当于函数内部的实现区别,也就是未就绪时是直接返回还是等待就绪;

而同步和异步是指访问数据的机制,同步一般指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞(区别就绪与读写二个阶段,同步的读写必须阻塞),异步则指主动请求数据后便可以继续处理其它任务,随后等待I/O,操作完毕的通知,这可以使进程在数据读写时也不阻塞。(等待"通知")

**Linux下的五种I/O模型**
* 阻塞I/O（blocking I/O）
* 非阻塞I/O （nonblocking I/O）
* I/O复用(select 和poll) （I/O multiplexing）
* 信号驱动I/O （signal driven I/O (SIGIO)）
* 异步I/O （asynchronous I/O (the POSIX aio_functions)）
前四种都是同步，只有最后一种才是异步IO。


**阻塞I/O模型：**
![](https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=3808372216,1260325684&fm=26&gp=0.jpg)
* 简介：进程会一直阻塞，直到数据拷贝完成

应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待….数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。

阻塞I/O模型图：在调用recv()/recvfrom（）函数时，发生在内核中等待数据和复制数据的过�����。

当调用recv()函数时，系统首先查是否有准备好的数据。如果数据没有准备好，那么系统就处于等待状态。当数据准备好后，将数据从系统缓冲区复制到用户空间，然后该函数返回。在套接应用程序中，当调用recv()函数时，未必用户空间就已经存在数据，那么此时recv()函数就会处于等待状态。

当使用socket()函数和WSASocket()函数创建套接字时，默认的套接字都是阻塞的。这意味着当调用Windows Sockets API不能立即完成时，线程处于等待状态，直到操作完成。

并不是所有Windows Sockets API以阻塞套接字为参数调用都会发生阻塞。例如，以阻塞模式的套接字为参数调用bind()、listen()函数时，函数会立即返回。将可能阻塞套接字的Windows Sockets API调用分为以下四种:

1．输入操作： recv()、recvfrom()、WSARecv()和WSARecvfrom()函数。以阻塞套接字为参数调用该函数接收数据。如果此时套接字缓冲区内没有数据可读，则调用线程在数据到来前一直睡眠。

2．输出操作： send()、sendto()、WSASend()和WSASendto()函数。以阻塞套接字为参数调用该函数发送数据。如果套接字缓冲区没有可用空间，线程会一直睡眠，直到有空间。

3．接受连接：accept()和WSAAcept()函数。以阻塞套接字为参数调用该函数，等待接受对方的连接请求。如果此时没有连接请求，线程就会进入睡眠状态。

4．外出连接：connect()和WSAConnect()函数。对于TCP连接，客户端以阻塞套接字为参数，调用该函数向服务器发起连接。该函数在收到服务器的应答前，不会返回。这意味着TCP连接总会等待至少到服务器的一次往返时间。

　　使用阻塞模式的套接字，开发网络程序比较简单，容易实现。当希望能够立即发送和接收数据，且处理的套接字数量比较少的情况下，使用阻塞模式来开发网络程序比较合适。

阻塞模式套接字的不足表现为，在大量建立好的套接字线程之间进行通信时比较困难。当使用“生产者-消费者”模型开发网络程序时，为每个套接字都分别分配一个读线程、一个处理数据线程和一个用于同步的事件，那么这样无疑加大系统的开销。其最大的缺点是当希望同时处理大量套接字时，将无从下手，其扩展性很差

**非阻塞IO模型** 
 ![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857412314&di=0d854bfa102034baf1b415032bb0cff8&imgtype=0&src=http%3A%2F%2Fpic.victorchu.info%2F%25E9%259D%259E%25E9%2598%25BB%25E5%25A1%259EIO.jpeg%3FimageView2%2F2%2Fw%2F800%2Fh%2F600%2Fq%2F75%257Cimageslim)

简介：非阻塞IO通过进程反复调用IO函数（多次系统调用，并马上返回）；在数据拷贝的过程中，进程是阻塞的；
 
我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。

把SOCKET设置为非阻塞模式，即通知系统内核：在调用Windows Sockets API时，不要让线程睡眠，而应该让函数立即返回。在返回时，该函数返回一个错误代码。图所示，一个非阻塞模式套接字多次调用recv()函数的过程。前三次调用recv()函数时，内核数据还没有准备好。因此，该函数立即返回WSAEWOULDBLOCK错误代码。第四次调用recv()函数时，数据已经准备好，被复制到应用程序的缓冲区中，recv()函数返回成功指示，应用程序开始处理数据。

当使用socket()函数和WSASocket()函数创建套接字时，默认都是阻���的。在创建套接字之后，通过调用ioctlsocket()函数，将该套接字设置为非阻塞模式。Linux下的函数是:fcntl().

套接字设置为非阻塞模式后，在调用Windows Sockets API函数时，调用函数会立即返回。大多数情况下，这些函数调用都会调用“失败”，并返回WSAEWOULDBLOCK错误代码。说明请求的操作在调用期间内没有时间完成。通常，应用程序需要重复调用该函数，直到获得成功返回代码。

需要说明的是并非所有的Windows Sockets API在非阻塞模式下调用，都会返回WSAEWOULDBLOCK错误。例如，以非阻塞模式的套接字为参数调用bind()函数时，就不会返回该错误代码。当然，在调用WSAStartup()函数时更不会返回该错误代码，因为该函数是应用程序第一调用的函数，当然不会返回这样的错误代码。

要将套接字设置为非阻塞模式，除了使用ioctlsocket()函数之外，还可以使用WSAAsyncselect()和WSAEventselect()函数。当调用该函数时，套接字会自动地设置为非阻塞方式。

由于使用非阻塞套接字在调用函数时，会经常返��WSAEWOULDBLOCK错误。所以在任何时候，都应仔细检查返回代码并作好对“失败”的准备。应用程序连续不断地调用这个函数，直到它返回成功指示为止。上面的程序清单中，在While循环体内不断地调用recv()函数，以读入1024个字节的数据。这种做法很浪费系统资源。

要完成这样的操作，有人使用MSG_PEEK标志调用recv()函数查看缓冲区中是否有数据可读。同样，这种方法也不好。因为该做法对系统造成的开销是很大的，并且应用程序至少要调用recv()函数两次，才能实际地读入数据。较好的做法是，使用套接字的“I/O模型”来判断非阻塞套接字是否可读可写。

非阻塞模式套接字与阻塞模式套接字相比，不容易使用。使用非阻塞模式套接字，需要编写更多的代码，以便在每个Windows Sockets API函数调用中，对收到的WSAEWOULDBLOCK错误进行处理。因此，非阻塞套接字便显得有些难于使用。

但是，非阻塞套接字在控制建立的多个连接，在数据的收发量不均，时间不定时，明显具有优势。这种套接字在使用上存在一定难度，但只要排除了这些困难，它在功能上还是非常强大的。通常情况下，可考虑使用套接字的“I/O模型”，它有助于应用程序通过异步方式，同时对一个或多个套接字的通信加以管理。


**IO复用模型：**
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857181158&di=13d24a895a5417ce847d6768a8f6f0f3&imgtype=jpg&src=http%3A%2F%2Fimg0.imgtn.bdimg.com%2Fit%2Fu%3D770609745%2C3299491672%26fm%3D214%26gp%3D0.jpg)

简介：主要是select和epoll；对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听；

I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。



**信号驱动IO**
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857276750&di=a736eec5e67ae951a456a8882f3b968d&imgtype=0&src=http%3A%2F%2Fimage.mamicode.com%2Finfo%2F201904%2F20190420195009891716.png) 

简介：两次调用，两次返回；

首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。



**异步IO模型**
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857069930&di=25759da9819bd9b52f14476aea277376&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20190624%2Ff5b1176ce6e241f48403c7e999d91b69.jpeg)

简介：数据拷贝的时候进程无需阻塞。

当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作


同步IO引起进程阻塞，直至IO操作完成。
异步IO不会引起进程阻塞。
IO复用是先通过select调用阻塞。

![](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=176532706,1323700702&fm=26&gp=0.jpg)

### 1.5.3. select&poll&epoll比较
<a href="#menu" >目录</a>


#### 1.5.3.1. 整体概览

**水平触发和边缘触发** 
* 水平触发通知
    * 如果文件描述符上可以非阻塞地执行I/O系统调用，此时认为它已经就绪
    * 也就是说主动去(轮询)检查文件描述符状态
    * select,poll,epoll
    * 可以任意时刻去检查文件描述符状态，因此不需要每次尽可能多的读取数据。
* 边缘触发通知
    * 如果文件描述符自上次状态检查以来有了新的I/O活动，此时需要触发通知。
    * select,信号驱动IO模型
    * I/O事件发生时才会收到通知型
    * 当收到通知时，应当尽可能多的读取字节，因为只有下一次I/O来时才能收到通知。


#### 1.5.3.2. 对比总结
epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现

**select：**
select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：
* 单个进程可监视的fd数量被限制，即能监听端口的大小有限。
一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.

* 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：
当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

* 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

* select函数
```c
int select(int nfds,fd_set *readfds,fd_set *writefds,fd_set *exceptfds, struct timeval *timeout)
```

* 参数
    * readfds 用来检测输入是否就绪的文件描述符集合
    * writefds 输出
    * exceptfds 异常情况是否发生
    * timeout  超时时间结构体
* 返回值
    * 0 ：超时
    * -1 ：发生错误
    * 大于1：就绪状态的描述符的总数，包括读写异常三个参数 
    

**poll：**

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：

* 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。
* poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

* poll 函数
```c
int poll(struct pollfd fds[],nfds_t nfds,int timeout)

struct pollfd{
    //文件描述符
    int fd;
    //请求事件位掩码
    short events; 
    //返回事件位源码
    short revents;
}
```


* 参数
    * nfds 指定fds的元素个数，nfds_t实际为无符号整形
    * fds-fd 文件描述符
    * fds-events 需要做检查的事件位掩码，调用者初始化
    * fds-revents 发生了事件的位掩码，内核设置并返回
    * timeout   
        * -1 : 一直阻塞直到有一个文件描述符发生事件
        * 0: 不阻塞，全部检查完即使没有事件也返回
        * 大于0:最多阻塞时间
* 返回:同select

**select poll区别**
* select 检查的文件描述符有数量上限(FD_SETZIZE),LINUX默认为1024，修改需要重新编译内核。poll没有限制

* select的fd_set同时也是保存调用结果的地方，如果多次调用select需要每次都要进行初始化。poll是两个参数存放检查和就绪的文件描述符，从而避免每次都要进行初始化。

* select提供的超时精度比poll高 



**select poll 问题**
* 每次调用select和epoll都要向内核传入需要检查的文件描述符，检测是否处于就绪状态。当检查的文件描述符较多时，将会很耗时
* select 和 poll调用完成以后，程序必须检查返回的数据结构中的每一个元素，以此查明哪个文件描述符处于就绪态。
* 每次调用select和epoll都要向内核传入需要检查的文件描述符，检查完成，又从内核返回应用，如果文件描述符过多，复制也很耗时。



**epoll:**
epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知

* 适用场景:
    * 同时处理许多客户端的服务器;
    * 需要监视大量的文件描述符，但大部分属于空闲状态，只有少数文件描述符处于就绪状态。

* epoll水平触发和边缘触发的区别
    * 例子
        * 套接字上有输入到来
        * 调用一次epoll_wait(),无论采用的是水平触发还是边缘触发，该调用都会告诉我们套接字已经给处于就绪态
        * 再次调用epoll_wait()
    * 说明
        * 如果是水平触发通知，第二个epoll_wait()会告诉我们套接字已经给处于就绪态
        * 如果是边缘触发通知，将会被阻塞，因为没有新的输入进来

* epoll边缘触发通知机制的程序基本框架
    * 让所有监视的文件描述符都成为非阻塞
    * 通过epoll_wait()取得就绪状态的描述符列表
    * 针对每一个处于就绪状态文件描述符，不断进行IO处理直到相关的系统调用(例如read,write,recv,send,accept)返回EAGAIN或EWOULDBLOCK错误 

epoll的接口非常简单，一共就三个函数：
1. int epoll_create(int size);
创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值。需要注意的是，当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。


2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
epoll的事件注册函数，它不同与select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。第一个参数是epoll_create()的返回值，第二个参数表示动作，用三个宏来表示：
EPOLL_CTL_ADD：注册新的fd到epfd中；
EPOLL_CTL_MOD：修改已经注册的fd的监听事件；
EPOLL_CTL_DEL：从epfd中删除一个fd；
第三个参数是需要监听的fd，第四个参数是告诉内核需要监听什么事，struct epoll_event结构如下：

```c
typedef union epoll_data {
    void *ptr;
    int fd;
    __uint32_t u32;
    __uint64_t u64;
} epoll_data_t;

struct epoll_event {
    __uint32_t events; /* Epoll events */
    epoll_data_t data; /* User data variable */
};

```
 


events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里


3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
等待事件的产生，类似于select()调用。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个 maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。


4、关于ET、LT两种工作模式：
可以得出这样的结论:
ET模式仅当状态发生变化的时候才获得通知,这里所谓的状态的变化并不包括缓冲区中还有未处理的数据,也就是说,如果要采用ET模式,需要一直read/write直到出错为止,很多人反映为什么采用ET模式只接收了一部分数据就再也得不到通知了,大多因为这样;而LT模式是只要有数据没有处理就会一直通知下去的.


那么究竟如何来使用epoll呢？其实非常简单。
通过在包含一个头文件#include <sys/epoll.h> 以及几个简单的API将可以大大的提高你的网络服务器的支持人数。

首先通过create_epoll(int maxfds)来创建一个epoll的句柄，其中maxfds为你epoll所支持的最大句柄数。这个函数会返回一个新的epoll句柄，之后的所有操作将通过这个句柄来进行操作。在用完之后，记得用close()来关闭这个创建出来的epoll句柄。

之后在你的网络主循环里面，每一帧的调用epoll_wait(int epfd, epoll_event events, int max events, int timeout)来查询所有的网络接口，看哪一个可以读，哪一个可以写了。基本的语法为：
nfds = epoll_wait(kdpfd, events, maxevents, -1);
其中kdpfd为用epoll_create创建之后的句柄，events是一个epoll_event*的指针，当epoll_wait这个函数操作成功之后，epoll_events里面将储存所有的读写事件。max_events是当前需要监听的所有socket句柄数。最后一个timeout是 epoll_wait的超时，为0的时候表示马上返回，为-1的时候表示一直等下去，直到有事件范围，为任意正整数的时候表示等这么长的时间，如果一直没有事件，则范围。一般如果网络主循环是单独的线程的话，可以用-1来等，这样可以保证一些效率，如果是和主逻辑在同一个线程的话，则可以用0来保证主循环的效率。

epoll_wait范围之后应该是一个循环，遍利所有的事件。

几乎所有的epoll程序都使用下面的框架：
```c
for( ; ; )
    {
        nfds = epoll_wait(epfd,events,20,500);
        for(i=0;i<nfds;++i)
        {
            if(events[i].data.fd==listenfd) //有新的连接
            {
                connfd = accept(listenfd,(sockaddr *)&clientaddr, &clilen); //accept这个连接
                ev.data.fd=connfd;
                ev.events=EPOLLIN|EPOLLET;
                epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&ev); //将新的fd添加到epoll的监听队列中
            }
            else if( events[i].events&EPOLLIN ) //接收到数据，读socket
            {
                n = read(sockfd, line, MAXLINE)) < 0    //读
                ev.data.ptr = md;     //md为自定义类型，添加数据
                ev.events=EPOLLOUT|EPOLLET;
                epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);//修改标识符，等待下一个循环时发送数据，异步处理的精髓
            }
            else if(events[i].events&EPOLLOUT) //有数据待发送，写socket
            {
                struct myepoll_data* md = (myepoll_data*)events[i].data.ptr;    //取数据
                sockfd = md->fd;
                send( sockfd, md->ptr, strlen((char*)md->ptr), 0 );        //发送数据
                ev.data.fd=sockfd;
                ev.events=EPOLLIN|EPOLLET;
                epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev); //修改标识符，等待下一个循环时接收数据
            }
            else
            {
                //其他的处理
            }
        }
    }

```
完整的服务端例子

```cpp
#include <iostream>
#include <sys/socket.h>
#include <sys/epoll.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>
#include <errno.h>

using namespace std;

#define MAXLINE 5
#define OPEN_MAX 100
#define LISTENQ 20
#define SERV_PORT 5000
#define INFTIM 1000

void setnonblocking(int sock)
{
    int opts;
    opts=fcntl(sock,F_GETFL);
    if(opts<0)
    {
        perror("fcntl(sock,GETFL)");
        exit(1);
    }
    opts = opts|O_NONBLOCK;
    if(fcntl(sock,F_SETFL,opts)<0)
    {
        perror("fcntl(sock,SETFL,opts)");
        exit(1);
    }
}

int main(int argc, char* argv[])
{
    int i, maxi, listenfd, connfd, sockfd,epfd,nfds, portnumber;
    ssize_t n;
    char line[MAXLINE];
    socklen_t clilen;


    if ( 2 == argc )
    {
        if( (portnumber = atoi(argv[1])) < 0 )
        {
            fprintf(stderr,"Usage:%s portnumber/a/n",argv[0]);
            return 1;
        }
    }
    else
    {
        fprintf(stderr,"Usage:%s portnumber/a/n",argv[0]);
        return 1;
    }



    //声明epoll_event结构体的变量,ev用于注册事件,数组用于回传要处理的事件

    struct epoll_event ev,events[20];
    //生成用于处理accept的epoll专用的文件描述符

    epfd=epoll_create(256);
    struct sockaddr_in clientaddr;
    struct sockaddr_in serveraddr;
    listenfd = socket(AF_INET, SOCK_STREAM, 0);
    //把socket设置为非阻塞方式

    //setnonblocking(listenfd);

    //设置与要处理的事件相关的文件描述符

    ev.data.fd=listenfd;
    //设置要处理的事件类型

    ev.events=EPOLLIN|EPOLLET;
    //ev.events=EPOLLIN;

    //注册epoll事件

    epoll_ctl(epfd,EPOLL_CTL_ADD,listenfd,&ev);
    bzero(&serveraddr, sizeof(serveraddr));
    serveraddr.sin_family = AF_INET;
    char *local_addr="127.0.0.1";
    inet_aton(local_addr,&(serveraddr.sin_addr));//htons(portnumber);

    serveraddr.sin_port=htons(portnumber);
    bind(listenfd,(sockaddr *)&serveraddr, sizeof(serveraddr));
    listen(listenfd, LISTENQ);
    maxi = 0;
    for ( ; ; ) {
        //等待epoll事件的发生

        nfds=epoll_wait(epfd,events,20,500);
        //处理所发生的所有事件

        for(i=0;i<nfds;++i)
        {
            if(events[i].data.fd==listenfd)//如果新监测到一个SOCKET用户连接到了绑定的SOCKET端口，建立新的连接。

            {
                connfd = accept(listenfd,(sockaddr *)&clientaddr, &clilen);
                if(connfd<0){
                    perror("connfd<0");
                    exit(1);
                }
                //setnonblocking(connfd);

                char *str = inet_ntoa(clientaddr.sin_addr);
                cout << "accapt a connection from " << str << endl;
                //设置用于读操作的文件描述符

                ev.data.fd=connfd;
                //设置用于注测的读操作事件

                ev.events=EPOLLIN|EPOLLET;
                //ev.events=EPOLLIN;

                //注册ev

                epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&ev);
            }
            else if(events[i].events&EPOLLIN)//如果是已经连接的用户，并且收到数据，那么进行读入。

            {
                cout << "EPOLLIN" << endl;
                if ( (sockfd = events[i].data.fd) < 0)
                    continue;
                if ( (n = read(sockfd, line, MAXLINE)) < 0) {
                    if (errno == ECONNRESET) {
                        close(sockfd);
                        events[i].data.fd = -1;
                    } else
                        std::cout<<"readline error"<<std::endl;
                } else if (n == 0) {
                    close(sockfd);
                    events[i].data.fd = -1;
                }
                line[n] = '/0';
                cout << "read " << line << endl;
                //设置用于写操作的文���描述符

                ev.data.fd=sockfd;
                //设置用于注测的写操作事件

                ev.events=EPOLLOUT|EPOLLET;
                //修改sockfd上要处理的事件为EPOLLOUT

                //epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);

            }
            else if(events[i].events&EPOLLOUT) // 如果有数据发送

            {
                sockfd = events[i].data.fd;
                write(sockfd, line, n);
                //设置用于读操作的文件描述符

                ev.data.fd=sockfd;
                //设置用于注测的读操作事件

                ev.events=EPOLLIN|EPOLLET;
                //修改sockfd上要处理的事件为EPOLIN

                epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);
            }
        }
    }
    return 0;
}
```

**select、poll、epoll 区别总结：** 

* 支持一个进程所能打开的最大连接数

|||
|---|---|
|select|单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。
|poll|poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的
|epoll|虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接

* FD剧增后带来的IO效率问题

|||
|---|---|
|select|因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。
|poll|同上
|epoll|因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

* 消息传递方式

|||
|---|---|
|select|内核需要将消息传递到用户空间，都需要内核拷贝动作
|poll|同上
|epoll|epoll通过内核和用户空间共享一块内存来实现的。

**总结：**
综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。
* 表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。
* select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善

